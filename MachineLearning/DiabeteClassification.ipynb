{"cells":[{"cell_type":"markdown","source":["### Machine Learning algorithms and Diabete"],"metadata":{}},{"cell_type":"code","source":["from pyspark.sql.functions import *\nfrom pyspark.sql import functions as fn\nfrom pyspark.sql.functions import mean, col, stddev\nfrom pyspark.mllib.util import MLUtils\nfrom pyspark.mllib.stat import Statistics\nimport pyspark.mllib.linalg\nfrom pyspark.mllib.linalg import Matrix, Matrices\nfrom pyspark.mllib.linalg.distributed import *\nfrom pyspark.mllib.linalg import Vectors\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.mllib.stat import KernelDensity\nfrom pyspark.mllib.linalg import Matrices, Vectors\nfrom pyspark.mllib.regression import LabeledPoint\nfrom numpy import array\nfrom pyspark.mllib.tree import DecisionTree\nfrom pyspark.mllib.linalg import DenseVector\nfrom pyspark.mllib.linalg import SparseVector\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pylab\nimport seaborn as sns\nfrom scipy.stats import norm\nimport scipy.stats as stats\nimport numpy as np\nimport statsmodels.api as sm\nfrom string import ascii_letters\nimport scipy.stats as ss\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import DecisionTreeClassifier\nfrom pyspark.ml.feature import PCA, VectorAssembler, StringIndexer\nfrom pyspark.ml.feature import Normalizer\n\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.classification import LogisticRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator\nfrom pyspark.ml.feature import HashingTF, Tokenizer\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder\nfrom pyspark.ml.evaluation import RegressionEvaluator\n\nfrom pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel, LogisticRegressionWithSGD\nfrom pyspark.mllib.regression import LabeledPoint\nfrom pyspark.ml.classification import GBTClassifier\nfrom pyspark.ml.feature import PCA\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml import Pipeline\n\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn import model_selection\nfrom sklearn.ensemble import  GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["!wget -O diabete.csv https://raw.githubusercontent.com/susanli2016/Machine-Learning-with-Python/master/diabetes.csv\ndf = pd.read_csv('diabete.csv') # panda dataframe\nspark_df = sqlContext.createDataFrame(df) # spark data frame"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["spark_df.printSchema()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- Pregnancies: long (nullable = true)\n-- Glucose: long (nullable = true)\n-- BloodPressure: long (nullable = true)\n-- SkinThickness: long (nullable = true)\n-- Insulin: long (nullable = true)\n-- BMI: double (nullable = true)\n-- DiabetesPedigreeFunction: double (nullable = true)\n-- Age: long (nullable = true)\n-- Outcome: long (nullable = true)\n\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["display(spark_df)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Pregnancies</th><th>Glucose</th><th>BloodPressure</th><th>SkinThickness</th><th>Insulin</th><th>BMI</th><th>DiabetesPedigreeFunction</th><th>Age</th><th>Outcome</th></tr></thead><tbody><tr><td>6</td><td>148</td><td>72</td><td>35</td><td>0</td><td>33.6</td><td>0.627</td><td>50</td><td>1</td></tr><tr><td>1</td><td>85</td><td>66</td><td>29</td><td>0</td><td>26.6</td><td>0.35100000000000003</td><td>31</td><td>0</td></tr><tr><td>8</td><td>183</td><td>64</td><td>0</td><td>0</td><td>23.3</td><td>0.672</td><td>32</td><td>1</td></tr><tr><td>1</td><td>89</td><td>66</td><td>23</td><td>94</td><td>28.1</td><td>0.16699999999999998</td><td>21</td><td>0</td></tr><tr><td>0</td><td>137</td><td>40</td><td>35</td><td>168</td><td>43.1</td><td>2.2880000000000003</td><td>33</td><td>1</td></tr><tr><td>5</td><td>116</td><td>74</td><td>0</td><td>0</td><td>25.6</td><td>0.201</td><td>30</td><td>0</td></tr><tr><td>3</td><td>78</td><td>50</td><td>32</td><td>88</td><td>31.0</td><td>0.248</td><td>26</td><td>1</td></tr><tr><td>10</td><td>115</td><td>0</td><td>0</td><td>0</td><td>35.3</td><td>0.134</td><td>29</td><td>0</td></tr><tr><td>2</td><td>197</td><td>70</td><td>45</td><td>543</td><td>30.5</td><td>0.158</td><td>53</td><td>1</td></tr><tr><td>8</td><td>125</td><td>96</td><td>0</td><td>0</td><td>0.0</td><td>0.23199999999999998</td><td>54</td><td>1</td></tr><tr><td>4</td><td>110</td><td>92</td><td>0</td><td>0</td><td>37.6</td><td>0.191</td><td>30</td><td>0</td></tr><tr><td>10</td><td>168</td><td>74</td><td>0</td><td>0</td><td>38.0</td><td>0.537</td><td>34</td><td>1</td></tr><tr><td>10</td><td>139</td><td>80</td><td>0</td><td>0</td><td>27.1</td><td>1.4409999999999998</td><td>57</td><td>0</td></tr><tr><td>1</td><td>189</td><td>60</td><td>23</td><td>846</td><td>30.1</td><td>0.39799999999999996</td><td>59</td><td>1</td></tr><tr><td>5</td><td>166</td><td>72</td><td>19</td><td>175</td><td>25.8</td><td>0.5870000000000001</td><td>51</td><td>1</td></tr><tr><td>7</td><td>100</td><td>0</td><td>0</td><td>0</td><td>30.0</td><td>0.484</td><td>32</td><td>1</td></tr><tr><td>0</td><td>118</td><td>84</td><td>47</td><td>230</td><td>45.8</td><td>0.551</td><td>31</td><td>1</td></tr><tr><td>7</td><td>107</td><td>74</td><td>0</td><td>0</td><td>29.6</td><td>0.254</td><td>31</td><td>1</td></tr><tr><td>1</td><td>103</td><td>30</td><td>38</td><td>83</td><td>43.3</td><td>0.183</td><td>33</td><td>0</td></tr><tr><td>1</td><td>115</td><td>70</td><td>30</td><td>96</td><td>34.6</td><td>0.529</td><td>32</td><td>1</td></tr><tr><td>3</td><td>126</td><td>88</td><td>41</td><td>235</td><td>39.3</td><td>0.7040000000000001</td><td>27</td><td>0</td></tr><tr><td>8</td><td>99</td><td>84</td><td>0</td><td>0</td><td>35.4</td><td>0.38799999999999996</td><td>50</td><td>0</td></tr><tr><td>7</td><td>196</td><td>90</td><td>0</td><td>0</td><td>39.8</td><td>0.451</td><td>41</td><td>1</td></tr><tr><td>9</td><td>119</td><td>80</td><td>35</td><td>0</td><td>29.0</td><td>0.263</td><td>29</td><td>1</td></tr><tr><td>11</td><td>143</td><td>94</td><td>33</td><td>146</td><td>36.6</td><td>0.254</td><td>51</td><td>1</td></tr><tr><td>10</td><td>125</td><td>70</td><td>26</td><td>115</td><td>31.1</td><td>0.205</td><td>41</td><td>1</td></tr><tr><td>7</td><td>147</td><td>76</td><td>0</td><td>0</td><td>39.4</td><td>0.257</td><td>43</td><td>1</td></tr><tr><td>1</td><td>97</td><td>66</td><td>15</td><td>140</td><td>23.2</td><td>0.48700000000000004</td><td>22</td><td>0</td></tr><tr><td>13</td><td>145</td><td>82</td><td>19</td><td>110</td><td>22.2</td><td>0.245</td><td>57</td><td>0</td></tr><tr><td>5</td><td>117</td><td>92</td><td>0</td><td>0</td><td>34.1</td><td>0.337</td><td>38</td><td>0</td></tr><tr><td>5</td><td>109</td><td>75</td><td>26</td><td>0</td><td>36.0</td><td>0.546</td><td>60</td><td>0</td></tr><tr><td>3</td><td>158</td><td>76</td><td>36</td><td>245</td><td>31.6</td><td>0.851</td><td>28</td><td>1</td></tr><tr><td>3</td><td>88</td><td>58</td><td>11</td><td>54</td><td>24.8</td><td>0.267</td><td>22</td><td>0</td></tr><tr><td>6</td><td>92</td><td>92</td><td>0</td><td>0</td><td>19.9</td><td>0.188</td><td>28</td><td>0</td></tr><tr><td>10</td><td>122</td><td>78</td><td>31</td><td>0</td><td>27.6</td><td>0.512</td><td>45</td><td>0</td></tr><tr><td>4</td><td>103</td><td>60</td><td>33</td><td>192</td><td>24.0</td><td>0.966</td><td>33</td><td>0</td></tr><tr><td>11</td><td>138</td><td>76</td><td>0</td><td>0</td><td>33.2</td><td>0.42</td><td>35</td><td>0</td></tr><tr><td>9</td><td>102</td><td>76</td><td>37</td><td>0</td><td>32.9</td><td>0.665</td><td>46</td><td>1</td></tr><tr><td>2</td><td>90</td><td>68</td><td>42</td><td>0</td><td>38.2</td><td>0.503</td><td>27</td><td>1</td></tr><tr><td>4</td><td>111</td><td>72</td><td>47</td><td>207</td><td>37.1</td><td>1.39</td><td>56</td><td>1</td></tr><tr><td>3</td><td>180</td><td>64</td><td>25</td><td>70</td><td>34.0</td><td>0.271</td><td>26</td><td>0</td></tr><tr><td>7</td><td>133</td><td>84</td><td>0</td><td>0</td><td>40.2</td><td>0.696</td><td>37</td><td>0</td></tr><tr><td>7</td><td>106</td><td>92</td><td>18</td><td>0</td><td>22.7</td><td>0.235</td><td>48</td><td>0</td></tr><tr><td>9</td><td>171</td><td>110</td><td>24</td><td>240</td><td>45.4</td><td>0.721</td><td>54</td><td>1</td></tr><tr><td>7</td><td>159</td><td>64</td><td>0</td><td>0</td><td>27.4</td><td>0.294</td><td>40</td><td>0</td></tr><tr><td>0</td><td>180</td><td>66</td><td>39</td><td>0</td><td>42.0</td><td>1.893</td><td>25</td><td>1</td></tr><tr><td>1</td><td>146</td><td>56</td><td>0</td><td>0</td><td>29.7</td><td>0.564</td><td>29</td><td>0</td></tr><tr><td>2</td><td>71</td><td>70</td><td>27</td><td>0</td><td>28.0</td><td>0.586</td><td>22</td><td>0</td></tr><tr><td>7</td><td>103</td><td>66</td><td>32</td><td>0</td><td>39.1</td><td>0.344</td><td>31</td><td>1</td></tr><tr><td>7</td><td>105</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.305</td><td>24</td><td>0</td></tr><tr><td>1</td><td>103</td><td>80</td><td>11</td><td>82</td><td>19.4</td><td>0.491</td><td>22</td><td>0</td></tr><tr><td>1</td><td>101</td><td>50</td><td>15</td><td>36</td><td>24.2</td><td>0.526</td><td>26</td><td>0</td></tr><tr><td>5</td><td>88</td><td>66</td><td>21</td><td>23</td><td>24.4</td><td>0.342</td><td>30</td><td>0</td></tr><tr><td>8</td><td>176</td><td>90</td><td>34</td><td>300</td><td>33.7</td><td>0.467</td><td>58</td><td>1</td></tr><tr><td>7</td><td>150</td><td>66</td><td>42</td><td>342</td><td>34.7</td><td>0.718</td><td>42</td><td>0</td></tr><tr><td>1</td><td>73</td><td>50</td><td>10</td><td>0</td><td>23.0</td><td>0.248</td><td>21</td><td>0</td></tr><tr><td>7</td><td>187</td><td>68</td><td>39</td><td>304</td><td>37.7</td><td>0.254</td><td>41</td><td>1</td></tr><tr><td>0</td><td>100</td><td>88</td><td>60</td><td>110</td><td>46.8</td><td>0.9620000000000001</td><td>31</td><td>0</td></tr><tr><td>0</td><td>146</td><td>82</td><td>0</td><td>0</td><td>40.5</td><td>1.781</td><td>44</td><td>0</td></tr><tr><td>0</td><td>105</td><td>64</td><td>41</td><td>142</td><td>41.5</td><td>0.17300000000000001</td><td>22</td><td>0</td></tr><tr><td>2</td><td>84</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.304</td><td>21</td><td>0</td></tr><tr><td>8</td><td>133</td><td>72</td><td>0</td><td>0</td><td>32.9</td><td>0.27</td><td>39</td><td>1</td></tr><tr><td>5</td><td>44</td><td>62</td><td>0</td><td>0</td><td>25.0</td><td>0.5870000000000001</td><td>36</td><td>0</td></tr><tr><td>2</td><td>141</td><td>58</td><td>34</td><td>128</td><td>25.4</td><td>0.6990000000000001</td><td>24</td><td>0</td></tr><tr><td>7</td><td>114</td><td>66</td><td>0</td><td>0</td><td>32.8</td><td>0.258</td><td>42</td><td>1</td></tr><tr><td>5</td><td>99</td><td>74</td><td>27</td><td>0</td><td>29.0</td><td>0.203</td><td>32</td><td>0</td></tr><tr><td>0</td><td>109</td><td>88</td><td>30</td><td>0</td><td>32.5</td><td>0.855</td><td>38</td><td>1</td></tr><tr><td>2</td><td>109</td><td>92</td><td>0</td><td>0</td><td>42.7</td><td>0.845</td><td>54</td><td>0</td></tr><tr><td>1</td><td>95</td><td>66</td><td>13</td><td>38</td><td>19.6</td><td>0.33399999999999996</td><td>25</td><td>0</td></tr><tr><td>4</td><td>146</td><td>85</td><td>27</td><td>100</td><td>28.9</td><td>0.18899999999999997</td><td>27</td><td>0</td></tr><tr><td>2</td><td>100</td><td>66</td><td>20</td><td>90</td><td>32.9</td><td>0.867</td><td>28</td><td>1</td></tr><tr><td>5</td><td>139</td><td>64</td><td>35</td><td>140</td><td>28.6</td><td>0.41100000000000003</td><td>26</td><td>0</td></tr><tr><td>13</td><td>126</td><td>90</td><td>0</td><td>0</td><td>43.4</td><td>0.583</td><td>42</td><td>1</td></tr><tr><td>4</td><td>129</td><td>86</td><td>20</td><td>270</td><td>35.1</td><td>0.231</td><td>23</td><td>0</td></tr><tr><td>1</td><td>79</td><td>75</td><td>30</td><td>0</td><td>32.0</td><td>0.396</td><td>22</td><td>0</td></tr><tr><td>1</td><td>0</td><td>48</td><td>20</td><td>0</td><td>24.7</td><td>0.14</td><td>22</td><td>0</td></tr><tr><td>7</td><td>62</td><td>78</td><td>0</td><td>0</td><td>32.6</td><td>0.391</td><td>41</td><td>0</td></tr><tr><td>5</td><td>95</td><td>72</td><td>33</td><td>0</td><td>37.7</td><td>0.37</td><td>27</td><td>0</td></tr><tr><td>0</td><td>131</td><td>0</td><td>0</td><td>0</td><td>43.2</td><td>0.27</td><td>26</td><td>1</td></tr><tr><td>2</td><td>112</td><td>66</td><td>22</td><td>0</td><td>25.0</td><td>0.307</td><td>24</td><td>0</td></tr><tr><td>3</td><td>113</td><td>44</td><td>13</td><td>0</td><td>22.4</td><td>0.14</td><td>22</td><td>0</td></tr><tr><td>2</td><td>74</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.102</td><td>22</td><td>0</td></tr><tr><td>7</td><td>83</td><td>78</td><td>26</td><td>71</td><td>29.3</td><td>0.767</td><td>36</td><td>0</td></tr><tr><td>0</td><td>101</td><td>65</td><td>28</td><td>0</td><td>24.6</td><td>0.237</td><td>22</td><td>0</td></tr><tr><td>5</td><td>137</td><td>108</td><td>0</td><td>0</td><td>48.8</td><td>0.22699999999999998</td><td>37</td><td>1</td></tr><tr><td>2</td><td>110</td><td>74</td><td>29</td><td>125</td><td>32.4</td><td>0.698</td><td>27</td><td>0</td></tr><tr><td>13</td><td>106</td><td>72</td><td>54</td><td>0</td><td>36.6</td><td>0.17800000000000002</td><td>45</td><td>0</td></tr><tr><td>2</td><td>100</td><td>68</td><td>25</td><td>71</td><td>38.5</td><td>0.324</td><td>26</td><td>0</td></tr><tr><td>15</td><td>136</td><td>70</td><td>32</td><td>110</td><td>37.1</td><td>0.153</td><td>43</td><td>1</td></tr><tr><td>1</td><td>107</td><td>68</td><td>19</td><td>0</td><td>26.5</td><td>0.165</td><td>24</td><td>0</td></tr><tr><td>1</td><td>80</td><td>55</td><td>0</td><td>0</td><td>19.1</td><td>0.258</td><td>21</td><td>0</td></tr><tr><td>4</td><td>123</td><td>80</td><td>15</td><td>176</td><td>32.0</td><td>0.44299999999999995</td><td>34</td><td>0</td></tr><tr><td>7</td><td>81</td><td>78</td><td>40</td><td>48</td><td>46.7</td><td>0.261</td><td>42</td><td>0</td></tr><tr><td>4</td><td>134</td><td>72</td><td>0</td><td>0</td><td>23.8</td><td>0.27699999999999997</td><td>60</td><td>1</td></tr><tr><td>2</td><td>142</td><td>82</td><td>18</td><td>64</td><td>24.7</td><td>0.7609999999999999</td><td>21</td><td>0</td></tr><tr><td>6</td><td>144</td><td>72</td><td>27</td><td>228</td><td>33.9</td><td>0.255</td><td>40</td><td>0</td></tr><tr><td>2</td><td>92</td><td>62</td><td>28</td><td>0</td><td>31.6</td><td>0.13</td><td>24</td><td>0</td></tr><tr><td>1</td><td>71</td><td>48</td><td>18</td><td>76</td><td>20.4</td><td>0.32299999999999995</td><td>22</td><td>0</td></tr><tr><td>6</td><td>93</td><td>50</td><td>30</td><td>64</td><td>28.7</td><td>0.35600000000000004</td><td>23</td><td>0</td></tr><tr><td>1</td><td>122</td><td>90</td><td>51</td><td>220</td><td>49.7</td><td>0.325</td><td>31</td><td>1</td></tr><tr><td>1</td><td>163</td><td>72</td><td>0</td><td>0</td><td>39.0</td><td>1.222</td><td>33</td><td>1</td></tr><tr><td>1</td><td>151</td><td>60</td><td>0</td><td>0</td><td>26.1</td><td>0.179</td><td>22</td><td>0</td></tr><tr><td>0</td><td>125</td><td>96</td><td>0</td><td>0</td><td>22.5</td><td>0.262</td><td>21</td><td>0</td></tr><tr><td>1</td><td>81</td><td>72</td><td>18</td><td>40</td><td>26.6</td><td>0.28300000000000003</td><td>24</td><td>0</td></tr><tr><td>2</td><td>85</td><td>65</td><td>0</td><td>0</td><td>39.6</td><td>0.93</td><td>27</td><td>0</td></tr><tr><td>1</td><td>126</td><td>56</td><td>29</td><td>152</td><td>28.7</td><td>0.8009999999999999</td><td>21</td><td>0</td></tr><tr><td>1</td><td>96</td><td>122</td><td>0</td><td>0</td><td>22.4</td><td>0.207</td><td>27</td><td>0</td></tr><tr><td>4</td><td>144</td><td>58</td><td>28</td><td>140</td><td>29.5</td><td>0.287</td><td>37</td><td>0</td></tr><tr><td>3</td><td>83</td><td>58</td><td>31</td><td>18</td><td>34.3</td><td>0.336</td><td>25</td><td>0</td></tr><tr><td>0</td><td>95</td><td>85</td><td>25</td><td>36</td><td>37.4</td><td>0.247</td><td>24</td><td>1</td></tr><tr><td>3</td><td>171</td><td>72</td><td>33</td><td>135</td><td>33.3</td><td>0.19899999999999998</td><td>24</td><td>1</td></tr><tr><td>8</td><td>155</td><td>62</td><td>26</td><td>495</td><td>34.0</td><td>0.5429999999999999</td><td>46</td><td>1</td></tr><tr><td>1</td><td>89</td><td>76</td><td>34</td><td>37</td><td>31.2</td><td>0.192</td><td>23</td><td>0</td></tr><tr><td>4</td><td>76</td><td>62</td><td>0</td><td>0</td><td>34.0</td><td>0.391</td><td>25</td><td>0</td></tr><tr><td>7</td><td>160</td><td>54</td><td>32</td><td>175</td><td>30.5</td><td>0.588</td><td>39</td><td>1</td></tr><tr><td>4</td><td>146</td><td>92</td><td>0</td><td>0</td><td>31.2</td><td>0.539</td><td>61</td><td>1</td></tr><tr><td>5</td><td>124</td><td>74</td><td>0</td><td>0</td><td>34.0</td><td>0.22</td><td>38</td><td>1</td></tr><tr><td>5</td><td>78</td><td>48</td><td>0</td><td>0</td><td>33.7</td><td>0.654</td><td>25</td><td>0</td></tr><tr><td>4</td><td>97</td><td>60</td><td>23</td><td>0</td><td>28.2</td><td>0.44299999999999995</td><td>22</td><td>0</td></tr><tr><td>4</td><td>99</td><td>76</td><td>15</td><td>51</td><td>23.2</td><td>0.223</td><td>21</td><td>0</td></tr><tr><td>0</td><td>162</td><td>76</td><td>56</td><td>100</td><td>53.2</td><td>0.759</td><td>25</td><td>1</td></tr><tr><td>6</td><td>111</td><td>64</td><td>39</td><td>0</td><td>34.2</td><td>0.26</td><td>24</td><td>0</td></tr><tr><td>2</td><td>107</td><td>74</td><td>30</td><td>100</td><td>33.6</td><td>0.40399999999999997</td><td>23</td><td>0</td></tr><tr><td>5</td><td>132</td><td>80</td><td>0</td><td>0</td><td>26.8</td><td>0.18600000000000003</td><td>69</td><td>0</td></tr><tr><td>0</td><td>113</td><td>76</td><td>0</td><td>0</td><td>33.3</td><td>0.278</td><td>23</td><td>1</td></tr><tr><td>1</td><td>88</td><td>30</td><td>42</td><td>99</td><td>55.0</td><td>0.496</td><td>26</td><td>1</td></tr><tr><td>3</td><td>120</td><td>70</td><td>30</td><td>135</td><td>42.9</td><td>0.452</td><td>30</td><td>0</td></tr><tr><td>1</td><td>118</td><td>58</td><td>36</td><td>94</td><td>33.3</td><td>0.261</td><td>23</td><td>0</td></tr><tr><td>1</td><td>117</td><td>88</td><td>24</td><td>145</td><td>34.5</td><td>0.40299999999999997</td><td>40</td><td>1</td></tr><tr><td>0</td><td>105</td><td>84</td><td>0</td><td>0</td><td>27.9</td><td>0.741</td><td>62</td><td>1</td></tr><tr><td>4</td><td>173</td><td>70</td><td>14</td><td>168</td><td>29.7</td><td>0.361</td><td>33</td><td>1</td></tr><tr><td>9</td><td>122</td><td>56</td><td>0</td><td>0</td><td>33.3</td><td>1.114</td><td>33</td><td>1</td></tr><tr><td>3</td><td>170</td><td>64</td><td>37</td><td>225</td><td>34.5</td><td>0.35600000000000004</td><td>30</td><td>1</td></tr><tr><td>8</td><td>84</td><td>74</td><td>31</td><td>0</td><td>38.3</td><td>0.457</td><td>39</td><td>0</td></tr><tr><td>2</td><td>96</td><td>68</td><td>13</td><td>49</td><td>21.1</td><td>0.647</td><td>26</td><td>0</td></tr><tr><td>2</td><td>125</td><td>60</td><td>20</td><td>140</td><td>33.8</td><td>0.08800000000000001</td><td>31</td><td>0</td></tr><tr><td>0</td><td>100</td><td>70</td><td>26</td><td>50</td><td>30.8</td><td>0.597</td><td>21</td><td>0</td></tr><tr><td>0</td><td>93</td><td>60</td><td>25</td><td>92</td><td>28.7</td><td>0.532</td><td>22</td><td>0</td></tr><tr><td>0</td><td>129</td><td>80</td><td>0</td><td>0</td><td>31.2</td><td>0.703</td><td>29</td><td>0</td></tr><tr><td>5</td><td>105</td><td>72</td><td>29</td><td>325</td><td>36.9</td><td>0.159</td><td>28</td><td>0</td></tr><tr><td>3</td><td>128</td><td>78</td><td>0</td><td>0</td><td>21.1</td><td>0.268</td><td>55</td><td>0</td></tr><tr><td>5</td><td>106</td><td>82</td><td>30</td><td>0</td><td>39.5</td><td>0.28600000000000003</td><td>38</td><td>0</td></tr><tr><td>2</td><td>108</td><td>52</td><td>26</td><td>63</td><td>32.5</td><td>0.318</td><td>22</td><td>0</td></tr><tr><td>10</td><td>108</td><td>66</td><td>0</td><td>0</td><td>32.4</td><td>0.272</td><td>42</td><td>1</td></tr><tr><td>4</td><td>154</td><td>62</td><td>31</td><td>284</td><td>32.8</td><td>0.237</td><td>23</td><td>0</td></tr><tr><td>0</td><td>102</td><td>75</td><td>23</td><td>0</td><td>0.0</td><td>0.5720000000000001</td><td>21</td><td>0</td></tr><tr><td>9</td><td>57</td><td>80</td><td>37</td><td>0</td><td>32.8</td><td>0.096</td><td>41</td><td>0</td></tr><tr><td>2</td><td>106</td><td>64</td><td>35</td><td>119</td><td>30.5</td><td>1.4</td><td>34</td><td>0</td></tr><tr><td>5</td><td>147</td><td>78</td><td>0</td><td>0</td><td>33.7</td><td>0.218</td><td>65</td><td>0</td></tr><tr><td>2</td><td>90</td><td>70</td><td>17</td><td>0</td><td>27.3</td><td>0.085</td><td>22</td><td>0</td></tr><tr><td>1</td><td>136</td><td>74</td><td>50</td><td>204</td><td>37.4</td><td>0.39899999999999997</td><td>24</td><td>0</td></tr><tr><td>4</td><td>114</td><td>65</td><td>0</td><td>0</td><td>21.9</td><td>0.43200000000000005</td><td>37</td><td>0</td></tr><tr><td>9</td><td>156</td><td>86</td><td>28</td><td>155</td><td>34.3</td><td>1.189</td><td>42</td><td>1</td></tr><tr><td>1</td><td>153</td><td>82</td><td>42</td><td>485</td><td>40.6</td><td>0.687</td><td>23</td><td>0</td></tr><tr><td>8</td><td>188</td><td>78</td><td>0</td><td>0</td><td>47.9</td><td>0.13699999999999998</td><td>43</td><td>1</td></tr><tr><td>7</td><td>152</td><td>88</td><td>44</td><td>0</td><td>50.0</td><td>0.337</td><td>36</td><td>1</td></tr><tr><td>2</td><td>99</td><td>52</td><td>15</td><td>94</td><td>24.6</td><td>0.637</td><td>21</td><td>0</td></tr><tr><td>1</td><td>109</td><td>56</td><td>21</td><td>135</td><td>25.2</td><td>0.833</td><td>23</td><td>0</td></tr><tr><td>2</td><td>88</td><td>74</td><td>19</td><td>53</td><td>29.0</td><td>0.22899999999999998</td><td>22</td><td>0</td></tr><tr><td>17</td><td>163</td><td>72</td><td>41</td><td>114</td><td>40.9</td><td>0.8170000000000001</td><td>47</td><td>1</td></tr><tr><td>4</td><td>151</td><td>90</td><td>38</td><td>0</td><td>29.7</td><td>0.294</td><td>36</td><td>0</td></tr><tr><td>7</td><td>102</td><td>74</td><td>40</td><td>105</td><td>37.2</td><td>0.204</td><td>45</td><td>0</td></tr><tr><td>0</td><td>114</td><td>80</td><td>34</td><td>285</td><td>44.2</td><td>0.16699999999999998</td><td>27</td><td>0</td></tr><tr><td>2</td><td>100</td><td>64</td><td>23</td><td>0</td><td>29.7</td><td>0.368</td><td>21</td><td>0</td></tr><tr><td>0</td><td>131</td><td>88</td><td>0</td><td>0</td><td>31.6</td><td>0.743</td><td>32</td><td>1</td></tr><tr><td>6</td><td>104</td><td>74</td><td>18</td><td>156</td><td>29.9</td><td>0.722</td><td>41</td><td>1</td></tr><tr><td>3</td><td>148</td><td>66</td><td>25</td><td>0</td><td>32.5</td><td>0.256</td><td>22</td><td>0</td></tr><tr><td>4</td><td>120</td><td>68</td><td>0</td><td>0</td><td>29.6</td><td>0.7090000000000001</td><td>34</td><td>0</td></tr><tr><td>4</td><td>110</td><td>66</td><td>0</td><td>0</td><td>31.9</td><td>0.47100000000000003</td><td>29</td><td>0</td></tr><tr><td>3</td><td>111</td><td>90</td><td>12</td><td>78</td><td>28.4</td><td>0.495</td><td>29</td><td>0</td></tr><tr><td>6</td><td>102</td><td>82</td><td>0</td><td>0</td><td>30.8</td><td>0.18</td><td>36</td><td>1</td></tr><tr><td>6</td><td>134</td><td>70</td><td>23</td><td>130</td><td>35.4</td><td>0.542</td><td>29</td><td>1</td></tr><tr><td>2</td><td>87</td><td>0</td><td>23</td><td>0</td><td>28.9</td><td>0.773</td><td>25</td><td>0</td></tr><tr><td>1</td><td>79</td><td>60</td><td>42</td><td>48</td><td>43.5</td><td>0.6779999999999999</td><td>23</td><td>0</td></tr><tr><td>2</td><td>75</td><td>64</td><td>24</td><td>55</td><td>29.7</td><td>0.37</td><td>33</td><td>0</td></tr><tr><td>8</td><td>179</td><td>72</td><td>42</td><td>130</td><td>32.7</td><td>0.7190000000000001</td><td>36</td><td>1</td></tr><tr><td>6</td><td>85</td><td>78</td><td>0</td><td>0</td><td>31.2</td><td>0.382</td><td>42</td><td>0</td></tr><tr><td>0</td><td>129</td><td>110</td><td>46</td><td>130</td><td>67.1</td><td>0.319</td><td>26</td><td>1</td></tr><tr><td>5</td><td>143</td><td>78</td><td>0</td><td>0</td><td>45.0</td><td>0.19</td><td>47</td><td>0</td></tr><tr><td>5</td><td>130</td><td>82</td><td>0</td><td>0</td><td>39.1</td><td>0.956</td><td>37</td><td>1</td></tr><tr><td>6</td><td>87</td><td>80</td><td>0</td><td>0</td><td>23.2</td><td>0.084</td><td>32</td><td>0</td></tr><tr><td>0</td><td>119</td><td>64</td><td>18</td><td>92</td><td>34.9</td><td>0.725</td><td>23</td><td>0</td></tr><tr><td>1</td><td>0</td><td>74</td><td>20</td><td>23</td><td>27.7</td><td>0.299</td><td>21</td><td>0</td></tr><tr><td>5</td><td>73</td><td>60</td><td>0</td><td>0</td><td>26.8</td><td>0.268</td><td>27</td><td>0</td></tr><tr><td>4</td><td>141</td><td>74</td><td>0</td><td>0</td><td>27.6</td><td>0.244</td><td>40</td><td>0</td></tr><tr><td>7</td><td>194</td><td>68</td><td>28</td><td>0</td><td>35.9</td><td>0.745</td><td>41</td><td>1</td></tr><tr><td>8</td><td>181</td><td>68</td><td>36</td><td>495</td><td>30.1</td><td>0.615</td><td>60</td><td>1</td></tr><tr><td>1</td><td>128</td><td>98</td><td>41</td><td>58</td><td>32.0</td><td>1.321</td><td>33</td><td>1</td></tr><tr><td>8</td><td>109</td><td>76</td><td>39</td><td>114</td><td>27.9</td><td>0.64</td><td>31</td><td>1</td></tr><tr><td>5</td><td>139</td><td>80</td><td>35</td><td>160</td><td>31.6</td><td>0.361</td><td>25</td><td>1</td></tr><tr><td>3</td><td>111</td><td>62</td><td>0</td><td>0</td><td>22.6</td><td>0.142</td><td>21</td><td>0</td></tr><tr><td>9</td><td>123</td><td>70</td><td>44</td><td>94</td><td>33.1</td><td>0.374</td><td>40</td><td>0</td></tr><tr><td>7</td><td>159</td><td>66</td><td>0</td><td>0</td><td>30.4</td><td>0.38299999999999995</td><td>36</td><td>1</td></tr><tr><td>11</td><td>135</td><td>0</td><td>0</td><td>0</td><td>52.3</td><td>0.578</td><td>40</td><td>1</td></tr><tr><td>8</td><td>85</td><td>55</td><td>20</td><td>0</td><td>24.4</td><td>0.136</td><td>42</td><td>0</td></tr><tr><td>5</td><td>158</td><td>84</td><td>41</td><td>210</td><td>39.4</td><td>0.395</td><td>29</td><td>1</td></tr><tr><td>1</td><td>105</td><td>58</td><td>0</td><td>0</td><td>24.3</td><td>0.187</td><td>21</td><td>0</td></tr><tr><td>3</td><td>107</td><td>62</td><td>13</td><td>48</td><td>22.9</td><td>0.6779999999999999</td><td>23</td><td>1</td></tr><tr><td>4</td><td>109</td><td>64</td><td>44</td><td>99</td><td>34.8</td><td>0.905</td><td>26</td><td>1</td></tr><tr><td>4</td><td>148</td><td>60</td><td>27</td><td>318</td><td>30.9</td><td>0.15</td><td>29</td><td>1</td></tr><tr><td>0</td><td>113</td><td>80</td><td>16</td><td>0</td><td>31.0</td><td>0.8740000000000001</td><td>21</td><td>0</td></tr><tr><td>1</td><td>138</td><td>82</td><td>0</td><td>0</td><td>40.1</td><td>0.23600000000000002</td><td>28</td><td>0</td></tr><tr><td>0</td><td>108</td><td>68</td><td>20</td><td>0</td><td>27.3</td><td>0.787</td><td>32</td><td>0</td></tr><tr><td>2</td><td>99</td><td>70</td><td>16</td><td>44</td><td>20.4</td><td>0.235</td><td>27</td><td>0</td></tr><tr><td>6</td><td>103</td><td>72</td><td>32</td><td>190</td><td>37.7</td><td>0.324</td><td>55</td><td>0</td></tr><tr><td>5</td><td>111</td><td>72</td><td>28</td><td>0</td><td>23.9</td><td>0.40700000000000003</td><td>27</td><td>0</td></tr><tr><td>8</td><td>196</td><td>76</td><td>29</td><td>280</td><td>37.5</td><td>0.605</td><td>57</td><td>1</td></tr><tr><td>5</td><td>162</td><td>104</td><td>0</td><td>0</td><td>37.7</td><td>0.151</td><td>52</td><td>1</td></tr><tr><td>1</td><td>96</td><td>64</td><td>27</td><td>87</td><td>33.2</td><td>0.289</td><td>21</td><td>0</td></tr><tr><td>7</td><td>184</td><td>84</td><td>33</td><td>0</td><td>35.5</td><td>0.355</td><td>41</td><td>1</td></tr><tr><td>2</td><td>81</td><td>60</td><td>22</td><td>0</td><td>27.7</td><td>0.29</td><td>25</td><td>0</td></tr><tr><td>0</td><td>147</td><td>85</td><td>54</td><td>0</td><td>42.8</td><td>0.375</td><td>24</td><td>0</td></tr><tr><td>7</td><td>179</td><td>95</td><td>31</td><td>0</td><td>34.2</td><td>0.16399999999999998</td><td>60</td><td>0</td></tr><tr><td>0</td><td>140</td><td>65</td><td>26</td><td>130</td><td>42.6</td><td>0.431</td><td>24</td><td>1</td></tr><tr><td>9</td><td>112</td><td>82</td><td>32</td><td>175</td><td>34.2</td><td>0.26</td><td>36</td><td>1</td></tr><tr><td>12</td><td>151</td><td>70</td><td>40</td><td>271</td><td>41.8</td><td>0.742</td><td>38</td><td>1</td></tr><tr><td>5</td><td>109</td><td>62</td><td>41</td><td>129</td><td>35.8</td><td>0.514</td><td>25</td><td>1</td></tr><tr><td>6</td><td>125</td><td>68</td><td>30</td><td>120</td><td>30.0</td><td>0.46399999999999997</td><td>32</td><td>0</td></tr><tr><td>5</td><td>85</td><td>74</td><td>22</td><td>0</td><td>29.0</td><td>1.224</td><td>32</td><td>1</td></tr><tr><td>5</td><td>112</td><td>66</td><td>0</td><td>0</td><td>37.8</td><td>0.261</td><td>41</td><td>1</td></tr><tr><td>0</td><td>177</td><td>60</td><td>29</td><td>478</td><td>34.6</td><td>1.072</td><td>21</td><td>1</td></tr><tr><td>2</td><td>158</td><td>90</td><td>0</td><td>0</td><td>31.6</td><td>0.805</td><td>66</td><td>1</td></tr><tr><td>7</td><td>119</td><td>0</td><td>0</td><td>0</td><td>25.2</td><td>0.209</td><td>37</td><td>0</td></tr><tr><td>7</td><td>142</td><td>60</td><td>33</td><td>190</td><td>28.8</td><td>0.687</td><td>61</td><td>0</td></tr><tr><td>1</td><td>100</td><td>66</td><td>15</td><td>56</td><td>23.6</td><td>0.6659999999999999</td><td>26</td><td>0</td></tr><tr><td>1</td><td>87</td><td>78</td><td>27</td><td>32</td><td>34.6</td><td>0.10099999999999999</td><td>22</td><td>0</td></tr><tr><td>0</td><td>101</td><td>76</td><td>0</td><td>0</td><td>35.7</td><td>0.198</td><td>26</td><td>0</td></tr><tr><td>3</td><td>162</td><td>52</td><td>38</td><td>0</td><td>37.2</td><td>0.652</td><td>24</td><td>1</td></tr><tr><td>4</td><td>197</td><td>70</td><td>39</td><td>744</td><td>36.7</td><td>2.329</td><td>31</td><td>0</td></tr><tr><td>0</td><td>117</td><td>80</td><td>31</td><td>53</td><td>45.2</td><td>0.08900000000000001</td><td>24</td><td>0</td></tr><tr><td>4</td><td>142</td><td>86</td><td>0</td><td>0</td><td>44.0</td><td>0.645</td><td>22</td><td>1</td></tr><tr><td>6</td><td>134</td><td>80</td><td>37</td><td>370</td><td>46.2</td><td>0.23800000000000002</td><td>46</td><td>1</td></tr><tr><td>1</td><td>79</td><td>80</td><td>25</td><td>37</td><td>25.4</td><td>0.583</td><td>22</td><td>0</td></tr><tr><td>4</td><td>122</td><td>68</td><td>0</td><td>0</td><td>35.0</td><td>0.39399999999999996</td><td>29</td><td>0</td></tr><tr><td>3</td><td>74</td><td>68</td><td>28</td><td>45</td><td>29.7</td><td>0.293</td><td>23</td><td>0</td></tr><tr><td>4</td><td>171</td><td>72</td><td>0</td><td>0</td><td>43.6</td><td>0.479</td><td>26</td><td>1</td></tr><tr><td>7</td><td>181</td><td>84</td><td>21</td><td>192</td><td>35.9</td><td>0.586</td><td>51</td><td>1</td></tr><tr><td>0</td><td>179</td><td>90</td><td>27</td><td>0</td><td>44.1</td><td>0.6859999999999999</td><td>23</td><td>1</td></tr><tr><td>9</td><td>164</td><td>84</td><td>21</td><td>0</td><td>30.8</td><td>0.831</td><td>32</td><td>1</td></tr><tr><td>0</td><td>104</td><td>76</td><td>0</td><td>0</td><td>18.4</td><td>0.5820000000000001</td><td>27</td><td>0</td></tr><tr><td>1</td><td>91</td><td>64</td><td>24</td><td>0</td><td>29.2</td><td>0.192</td><td>21</td><td>0</td></tr><tr><td>4</td><td>91</td><td>70</td><td>32</td><td>88</td><td>33.1</td><td>0.446</td><td>22</td><td>0</td></tr><tr><td>3</td><td>139</td><td>54</td><td>0</td><td>0</td><td>25.6</td><td>0.402</td><td>22</td><td>1</td></tr><tr><td>6</td><td>119</td><td>50</td><td>22</td><td>176</td><td>27.1</td><td>1.318</td><td>33</td><td>1</td></tr><tr><td>2</td><td>146</td><td>76</td><td>35</td><td>194</td><td>38.2</td><td>0.32899999999999996</td><td>29</td><td>0</td></tr><tr><td>9</td><td>184</td><td>85</td><td>15</td><td>0</td><td>30.0</td><td>1.213</td><td>49</td><td>1</td></tr><tr><td>10</td><td>122</td><td>68</td><td>0</td><td>0</td><td>31.2</td><td>0.258</td><td>41</td><td>0</td></tr><tr><td>0</td><td>165</td><td>90</td><td>33</td><td>680</td><td>52.3</td><td>0.42700000000000005</td><td>23</td><td>0</td></tr><tr><td>9</td><td>124</td><td>70</td><td>33</td><td>402</td><td>35.4</td><td>0.282</td><td>34</td><td>0</td></tr><tr><td>1</td><td>111</td><td>86</td><td>19</td><td>0</td><td>30.1</td><td>0.14300000000000002</td><td>23</td><td>0</td></tr><tr><td>9</td><td>106</td><td>52</td><td>0</td><td>0</td><td>31.2</td><td>0.38</td><td>42</td><td>0</td></tr><tr><td>2</td><td>129</td><td>84</td><td>0</td><td>0</td><td>28.0</td><td>0.284</td><td>27</td><td>0</td></tr><tr><td>2</td><td>90</td><td>80</td><td>14</td><td>55</td><td>24.4</td><td>0.249</td><td>24</td><td>0</td></tr><tr><td>0</td><td>86</td><td>68</td><td>32</td><td>0</td><td>35.8</td><td>0.23800000000000002</td><td>25</td><td>0</td></tr><tr><td>12</td><td>92</td><td>62</td><td>7</td><td>258</td><td>27.6</td><td>0.9259999999999999</td><td>44</td><td>1</td></tr><tr><td>1</td><td>113</td><td>64</td><td>35</td><td>0</td><td>33.6</td><td>0.5429999999999999</td><td>21</td><td>1</td></tr><tr><td>3</td><td>111</td><td>56</td><td>39</td><td>0</td><td>30.1</td><td>0.557</td><td>30</td><td>0</td></tr><tr><td>2</td><td>114</td><td>68</td><td>22</td><td>0</td><td>28.7</td><td>0.092</td><td>25</td><td>0</td></tr><tr><td>1</td><td>193</td><td>50</td><td>16</td><td>375</td><td>25.9</td><td>0.655</td><td>24</td><td>0</td></tr><tr><td>11</td><td>155</td><td>76</td><td>28</td><td>150</td><td>33.3</td><td>1.3530000000000002</td><td>51</td><td>1</td></tr><tr><td>3</td><td>191</td><td>68</td><td>15</td><td>130</td><td>30.9</td><td>0.299</td><td>34</td><td>0</td></tr><tr><td>3</td><td>141</td><td>0</td><td>0</td><td>0</td><td>30.0</td><td>0.7609999999999999</td><td>27</td><td>1</td></tr><tr><td>4</td><td>95</td><td>70</td><td>32</td><td>0</td><td>32.1</td><td>0.612</td><td>24</td><td>0</td></tr><tr><td>3</td><td>142</td><td>80</td><td>15</td><td>0</td><td>32.4</td><td>0.2</td><td>63</td><td>0</td></tr><tr><td>4</td><td>123</td><td>62</td><td>0</td><td>0</td><td>32.0</td><td>0.226</td><td>35</td><td>1</td></tr><tr><td>5</td><td>96</td><td>74</td><td>18</td><td>67</td><td>33.6</td><td>0.997</td><td>43</td><td>0</td></tr><tr><td>0</td><td>138</td><td>0</td><td>0</td><td>0</td><td>36.3</td><td>0.9329999999999999</td><td>25</td><td>1</td></tr><tr><td>2</td><td>128</td><td>64</td><td>42</td><td>0</td><td>40.0</td><td>1.101</td><td>24</td><td>0</td></tr><tr><td>0</td><td>102</td><td>52</td><td>0</td><td>0</td><td>25.1</td><td>0.078</td><td>21</td><td>0</td></tr><tr><td>2</td><td>146</td><td>0</td><td>0</td><td>0</td><td>27.5</td><td>0.24</td><td>28</td><td>1</td></tr><tr><td>10</td><td>101</td><td>86</td><td>37</td><td>0</td><td>45.6</td><td>1.136</td><td>38</td><td>1</td></tr><tr><td>2</td><td>108</td><td>62</td><td>32</td><td>56</td><td>25.2</td><td>0.128</td><td>21</td><td>0</td></tr><tr><td>3</td><td>122</td><td>78</td><td>0</td><td>0</td><td>23.0</td><td>0.254</td><td>40</td><td>0</td></tr><tr><td>1</td><td>71</td><td>78</td><td>50</td><td>45</td><td>33.2</td><td>0.42200000000000004</td><td>21</td><td>0</td></tr><tr><td>13</td><td>106</td><td>70</td><td>0</td><td>0</td><td>34.2</td><td>0.251</td><td>52</td><td>0</td></tr><tr><td>2</td><td>100</td><td>70</td><td>52</td><td>57</td><td>40.5</td><td>0.677</td><td>25</td><td>0</td></tr><tr><td>7</td><td>106</td><td>60</td><td>24</td><td>0</td><td>26.5</td><td>0.29600000000000004</td><td>29</td><td>1</td></tr><tr><td>0</td><td>104</td><td>64</td><td>23</td><td>116</td><td>27.8</td><td>0.45399999999999996</td><td>23</td><td>0</td></tr><tr><td>5</td><td>114</td><td>74</td><td>0</td><td>0</td><td>24.9</td><td>0.7440000000000001</td><td>57</td><td>0</td></tr><tr><td>2</td><td>108</td><td>62</td><td>10</td><td>278</td><td>25.3</td><td>0.8809999999999999</td><td>22</td><td>0</td></tr><tr><td>0</td><td>146</td><td>70</td><td>0</td><td>0</td><td>37.9</td><td>0.33399999999999996</td><td>28</td><td>1</td></tr><tr><td>10</td><td>129</td><td>76</td><td>28</td><td>122</td><td>35.9</td><td>0.28</td><td>39</td><td>0</td></tr><tr><td>7</td><td>133</td><td>88</td><td>15</td><td>155</td><td>32.4</td><td>0.262</td><td>37</td><td>0</td></tr><tr><td>7</td><td>161</td><td>86</td><td>0</td><td>0</td><td>30.4</td><td>0.165</td><td>47</td><td>1</td></tr><tr><td>2</td><td>108</td><td>80</td><td>0</td><td>0</td><td>27.0</td><td>0.259</td><td>52</td><td>1</td></tr><tr><td>7</td><td>136</td><td>74</td><td>26</td><td>135</td><td>26.0</td><td>0.647</td><td>51</td><td>0</td></tr><tr><td>5</td><td>155</td><td>84</td><td>44</td><td>545</td><td>38.7</td><td>0.619</td><td>34</td><td>0</td></tr><tr><td>1</td><td>119</td><td>86</td><td>39</td><td>220</td><td>45.6</td><td>0.8079999999999999</td><td>29</td><td>1</td></tr><tr><td>4</td><td>96</td><td>56</td><td>17</td><td>49</td><td>20.8</td><td>0.34</td><td>26</td><td>0</td></tr><tr><td>5</td><td>108</td><td>72</td><td>43</td><td>75</td><td>36.1</td><td>0.263</td><td>33</td><td>0</td></tr><tr><td>0</td><td>78</td><td>88</td><td>29</td><td>40</td><td>36.9</td><td>0.434</td><td>21</td><td>0</td></tr><tr><td>0</td><td>107</td><td>62</td><td>30</td><td>74</td><td>36.6</td><td>0.757</td><td>25</td><td>1</td></tr><tr><td>2</td><td>128</td><td>78</td><td>37</td><td>182</td><td>43.3</td><td>1.224</td><td>31</td><td>1</td></tr><tr><td>1</td><td>128</td><td>48</td><td>45</td><td>194</td><td>40.5</td><td>0.613</td><td>24</td><td>1</td></tr><tr><td>0</td><td>161</td><td>50</td><td>0</td><td>0</td><td>21.9</td><td>0.254</td><td>65</td><td>0</td></tr><tr><td>6</td><td>151</td><td>62</td><td>31</td><td>120</td><td>35.5</td><td>0.6920000000000001</td><td>28</td><td>0</td></tr><tr><td>2</td><td>146</td><td>70</td><td>38</td><td>360</td><td>28.0</td><td>0.337</td><td>29</td><td>1</td></tr><tr><td>0</td><td>126</td><td>84</td><td>29</td><td>215</td><td>30.7</td><td>0.52</td><td>24</td><td>0</td></tr><tr><td>14</td><td>100</td><td>78</td><td>25</td><td>184</td><td>36.6</td><td>0.41200000000000003</td><td>46</td><td>1</td></tr><tr><td>8</td><td>112</td><td>72</td><td>0</td><td>0</td><td>23.6</td><td>0.84</td><td>58</td><td>0</td></tr><tr><td>0</td><td>167</td><td>0</td><td>0</td><td>0</td><td>32.3</td><td>0.8390000000000001</td><td>30</td><td>1</td></tr><tr><td>2</td><td>144</td><td>58</td><td>33</td><td>135</td><td>31.6</td><td>0.42200000000000004</td><td>25</td><td>1</td></tr><tr><td>5</td><td>77</td><td>82</td><td>41</td><td>42</td><td>35.8</td><td>0.156</td><td>35</td><td>0</td></tr><tr><td>5</td><td>115</td><td>98</td><td>0</td><td>0</td><td>52.9</td><td>0.209</td><td>28</td><td>1</td></tr><tr><td>3</td><td>150</td><td>76</td><td>0</td><td>0</td><td>21.0</td><td>0.207</td><td>37</td><td>0</td></tr><tr><td>2</td><td>120</td><td>76</td><td>37</td><td>105</td><td>39.7</td><td>0.215</td><td>29</td><td>0</td></tr><tr><td>10</td><td>161</td><td>68</td><td>23</td><td>132</td><td>25.5</td><td>0.326</td><td>47</td><td>1</td></tr><tr><td>0</td><td>137</td><td>68</td><td>14</td><td>148</td><td>24.8</td><td>0.14300000000000002</td><td>21</td><td>0</td></tr><tr><td>0</td><td>128</td><td>68</td><td>19</td><td>180</td><td>30.5</td><td>1.391</td><td>25</td><td>1</td></tr><tr><td>2</td><td>124</td><td>68</td><td>28</td><td>205</td><td>32.9</td><td>0.875</td><td>30</td><td>1</td></tr><tr><td>6</td><td>80</td><td>66</td><td>30</td><td>0</td><td>26.2</td><td>0.313</td><td>41</td><td>0</td></tr><tr><td>0</td><td>106</td><td>70</td><td>37</td><td>148</td><td>39.4</td><td>0.605</td><td>22</td><td>0</td></tr><tr><td>2</td><td>155</td><td>74</td><td>17</td><td>96</td><td>26.6</td><td>0.433</td><td>27</td><td>1</td></tr><tr><td>3</td><td>113</td><td>50</td><td>10</td><td>85</td><td>29.5</td><td>0.626</td><td>25</td><td>0</td></tr><tr><td>7</td><td>109</td><td>80</td><td>31</td><td>0</td><td>35.9</td><td>1.127</td><td>43</td><td>1</td></tr><tr><td>2</td><td>112</td><td>68</td><td>22</td><td>94</td><td>34.1</td><td>0.315</td><td>26</td><td>0</td></tr><tr><td>3</td><td>99</td><td>80</td><td>11</td><td>64</td><td>19.3</td><td>0.284</td><td>30</td><td>0</td></tr><tr><td>3</td><td>182</td><td>74</td><td>0</td><td>0</td><td>30.5</td><td>0.345</td><td>29</td><td>1</td></tr><tr><td>3</td><td>115</td><td>66</td><td>39</td><td>140</td><td>38.1</td><td>0.15</td><td>28</td><td>0</td></tr><tr><td>6</td><td>194</td><td>78</td><td>0</td><td>0</td><td>23.5</td><td>0.129</td><td>59</td><td>1</td></tr><tr><td>4</td><td>129</td><td>60</td><td>12</td><td>231</td><td>27.5</td><td>0.527</td><td>31</td><td>0</td></tr><tr><td>3</td><td>112</td><td>74</td><td>30</td><td>0</td><td>31.6</td><td>0.19699999999999998</td><td>25</td><td>1</td></tr><tr><td>0</td><td>124</td><td>70</td><td>20</td><td>0</td><td>27.4</td><td>0.254</td><td>36</td><td>1</td></tr><tr><td>13</td><td>152</td><td>90</td><td>33</td><td>29</td><td>26.8</td><td>0.731</td><td>43</td><td>1</td></tr><tr><td>2</td><td>112</td><td>75</td><td>32</td><td>0</td><td>35.7</td><td>0.14800000000000002</td><td>21</td><td>0</td></tr><tr><td>1</td><td>157</td><td>72</td><td>21</td><td>168</td><td>25.6</td><td>0.12300000000000001</td><td>24</td><td>0</td></tr><tr><td>1</td><td>122</td><td>64</td><td>32</td><td>156</td><td>35.1</td><td>0.6920000000000001</td><td>30</td><td>1</td></tr><tr><td>10</td><td>179</td><td>70</td><td>0</td><td>0</td><td>35.1</td><td>0.2</td><td>37</td><td>0</td></tr><tr><td>2</td><td>102</td><td>86</td><td>36</td><td>120</td><td>45.5</td><td>0.127</td><td>23</td><td>1</td></tr><tr><td>6</td><td>105</td><td>70</td><td>32</td><td>68</td><td>30.8</td><td>0.122</td><td>37</td><td>0</td></tr><tr><td>8</td><td>118</td><td>72</td><td>19</td><td>0</td><td>23.1</td><td>1.476</td><td>46</td><td>0</td></tr><tr><td>2</td><td>87</td><td>58</td><td>16</td><td>52</td><td>32.7</td><td>0.166</td><td>25</td><td>0</td></tr><tr><td>1</td><td>180</td><td>0</td><td>0</td><td>0</td><td>43.3</td><td>0.282</td><td>41</td><td>1</td></tr><tr><td>12</td><td>106</td><td>80</td><td>0</td><td>0</td><td>23.6</td><td>0.13699999999999998</td><td>44</td><td>0</td></tr><tr><td>1</td><td>95</td><td>60</td><td>18</td><td>58</td><td>23.9</td><td>0.26</td><td>22</td><td>0</td></tr><tr><td>0</td><td>165</td><td>76</td><td>43</td><td>255</td><td>47.9</td><td>0.259</td><td>26</td><td>0</td></tr><tr><td>0</td><td>117</td><td>0</td><td>0</td><td>0</td><td>33.8</td><td>0.932</td><td>44</td><td>0</td></tr><tr><td>5</td><td>115</td><td>76</td><td>0</td><td>0</td><td>31.2</td><td>0.34299999999999997</td><td>44</td><td>1</td></tr><tr><td>9</td><td>152</td><td>78</td><td>34</td><td>171</td><td>34.2</td><td>0.893</td><td>33</td><td>1</td></tr><tr><td>7</td><td>178</td><td>84</td><td>0</td><td>0</td><td>39.9</td><td>0.331</td><td>41</td><td>1</td></tr><tr><td>1</td><td>130</td><td>70</td><td>13</td><td>105</td><td>25.9</td><td>0.47200000000000003</td><td>22</td><td>0</td></tr><tr><td>1</td><td>95</td><td>74</td><td>21</td><td>73</td><td>25.9</td><td>0.6729999999999999</td><td>36</td><td>0</td></tr><tr><td>1</td><td>0</td><td>68</td><td>35</td><td>0</td><td>32.0</td><td>0.389</td><td>22</td><td>0</td></tr><tr><td>5</td><td>122</td><td>86</td><td>0</td><td>0</td><td>34.7</td><td>0.29</td><td>33</td><td>0</td></tr><tr><td>8</td><td>95</td><td>72</td><td>0</td><td>0</td><td>36.8</td><td>0.485</td><td>57</td><td>0</td></tr><tr><td>8</td><td>126</td><td>88</td><td>36</td><td>108</td><td>38.5</td><td>0.349</td><td>49</td><td>0</td></tr><tr><td>1</td><td>139</td><td>46</td><td>19</td><td>83</td><td>28.7</td><td>0.654</td><td>22</td><td>0</td></tr><tr><td>3</td><td>116</td><td>0</td><td>0</td><td>0</td><td>23.5</td><td>0.187</td><td>23</td><td>0</td></tr><tr><td>3</td><td>99</td><td>62</td><td>19</td><td>74</td><td>21.8</td><td>0.27899999999999997</td><td>26</td><td>0</td></tr><tr><td>5</td><td>0</td><td>80</td><td>32</td><td>0</td><td>41.0</td><td>0.34600000000000003</td><td>37</td><td>1</td></tr><tr><td>4</td><td>92</td><td>80</td><td>0</td><td>0</td><td>42.2</td><td>0.237</td><td>29</td><td>0</td></tr><tr><td>4</td><td>137</td><td>84</td><td>0</td><td>0</td><td>31.2</td><td>0.252</td><td>30</td><td>0</td></tr><tr><td>3</td><td>61</td><td>82</td><td>28</td><td>0</td><td>34.4</td><td>0.243</td><td>46</td><td>0</td></tr><tr><td>1</td><td>90</td><td>62</td><td>12</td><td>43</td><td>27.2</td><td>0.58</td><td>24</td><td>0</td></tr><tr><td>3</td><td>90</td><td>78</td><td>0</td><td>0</td><td>42.7</td><td>0.5589999999999999</td><td>21</td><td>0</td></tr><tr><td>9</td><td>165</td><td>88</td><td>0</td><td>0</td><td>30.4</td><td>0.302</td><td>49</td><td>1</td></tr><tr><td>1</td><td>125</td><td>50</td><td>40</td><td>167</td><td>33.3</td><td>0.9620000000000001</td><td>28</td><td>1</td></tr><tr><td>13</td><td>129</td><td>0</td><td>30</td><td>0</td><td>39.9</td><td>0.569</td><td>44</td><td>1</td></tr><tr><td>12</td><td>88</td><td>74</td><td>40</td><td>54</td><td>35.3</td><td>0.37799999999999995</td><td>48</td><td>0</td></tr><tr><td>1</td><td>196</td><td>76</td><td>36</td><td>249</td><td>36.5</td><td>0.875</td><td>29</td><td>1</td></tr><tr><td>5</td><td>189</td><td>64</td><td>33</td><td>325</td><td>31.2</td><td>0.583</td><td>29</td><td>1</td></tr><tr><td>5</td><td>158</td><td>70</td><td>0</td><td>0</td><td>29.8</td><td>0.207</td><td>63</td><td>0</td></tr><tr><td>5</td><td>103</td><td>108</td><td>37</td><td>0</td><td>39.2</td><td>0.305</td><td>65</td><td>0</td></tr><tr><td>4</td><td>146</td><td>78</td><td>0</td><td>0</td><td>38.5</td><td>0.52</td><td>67</td><td>1</td></tr><tr><td>4</td><td>147</td><td>74</td><td>25</td><td>293</td><td>34.9</td><td>0.385</td><td>30</td><td>0</td></tr><tr><td>5</td><td>99</td><td>54</td><td>28</td><td>83</td><td>34.0</td><td>0.499</td><td>30</td><td>0</td></tr><tr><td>6</td><td>124</td><td>72</td><td>0</td><td>0</td><td>27.6</td><td>0.368</td><td>29</td><td>1</td></tr><tr><td>0</td><td>101</td><td>64</td><td>17</td><td>0</td><td>21.0</td><td>0.252</td><td>21</td><td>0</td></tr><tr><td>3</td><td>81</td><td>86</td><td>16</td><td>66</td><td>27.5</td><td>0.306</td><td>22</td><td>0</td></tr><tr><td>1</td><td>133</td><td>102</td><td>28</td><td>140</td><td>32.8</td><td>0.23399999999999999</td><td>45</td><td>1</td></tr><tr><td>3</td><td>173</td><td>82</td><td>48</td><td>465</td><td>38.4</td><td>2.137</td><td>25</td><td>1</td></tr><tr><td>0</td><td>118</td><td>64</td><td>23</td><td>89</td><td>0.0</td><td>1.7309999999999999</td><td>21</td><td>0</td></tr><tr><td>0</td><td>84</td><td>64</td><td>22</td><td>66</td><td>35.8</td><td>0.545</td><td>21</td><td>0</td></tr><tr><td>2</td><td>105</td><td>58</td><td>40</td><td>94</td><td>34.9</td><td>0.225</td><td>25</td><td>0</td></tr><tr><td>2</td><td>122</td><td>52</td><td>43</td><td>158</td><td>36.2</td><td>0.816</td><td>28</td><td>0</td></tr><tr><td>12</td><td>140</td><td>82</td><td>43</td><td>325</td><td>39.2</td><td>0.528</td><td>58</td><td>1</td></tr><tr><td>0</td><td>98</td><td>82</td><td>15</td><td>84</td><td>25.2</td><td>0.299</td><td>22</td><td>0</td></tr><tr><td>1</td><td>87</td><td>60</td><td>37</td><td>75</td><td>37.2</td><td>0.509</td><td>22</td><td>0</td></tr><tr><td>4</td><td>156</td><td>75</td><td>0</td><td>0</td><td>48.3</td><td>0.23800000000000002</td><td>32</td><td>1</td></tr><tr><td>0</td><td>93</td><td>100</td><td>39</td><td>72</td><td>43.4</td><td>1.021</td><td>35</td><td>0</td></tr><tr><td>1</td><td>107</td><td>72</td><td>30</td><td>82</td><td>30.8</td><td>0.821</td><td>24</td><td>0</td></tr><tr><td>0</td><td>105</td><td>68</td><td>22</td><td>0</td><td>20.0</td><td>0.23600000000000002</td><td>22</td><td>0</td></tr><tr><td>1</td><td>109</td><td>60</td><td>8</td><td>182</td><td>25.4</td><td>0.9470000000000001</td><td>21</td><td>0</td></tr><tr><td>1</td><td>90</td><td>62</td><td>18</td><td>59</td><td>25.1</td><td>1.268</td><td>25</td><td>0</td></tr><tr><td>1</td><td>125</td><td>70</td><td>24</td><td>110</td><td>24.3</td><td>0.221</td><td>25</td><td>0</td></tr><tr><td>1</td><td>119</td><td>54</td><td>13</td><td>50</td><td>22.3</td><td>0.205</td><td>24</td><td>0</td></tr><tr><td>5</td><td>116</td><td>74</td><td>29</td><td>0</td><td>32.3</td><td>0.66</td><td>35</td><td>1</td></tr><tr><td>8</td><td>105</td><td>100</td><td>36</td><td>0</td><td>43.3</td><td>0.239</td><td>45</td><td>1</td></tr><tr><td>5</td><td>144</td><td>82</td><td>26</td><td>285</td><td>32.0</td><td>0.452</td><td>58</td><td>1</td></tr><tr><td>3</td><td>100</td><td>68</td><td>23</td><td>81</td><td>31.6</td><td>0.9490000000000001</td><td>28</td><td>0</td></tr><tr><td>1</td><td>100</td><td>66</td><td>29</td><td>196</td><td>32.0</td><td>0.444</td><td>42</td><td>0</td></tr><tr><td>5</td><td>166</td><td>76</td><td>0</td><td>0</td><td>45.7</td><td>0.34</td><td>27</td><td>1</td></tr><tr><td>1</td><td>131</td><td>64</td><td>14</td><td>415</td><td>23.7</td><td>0.389</td><td>21</td><td>0</td></tr><tr><td>4</td><td>116</td><td>72</td><td>12</td><td>87</td><td>22.1</td><td>0.46299999999999997</td><td>37</td><td>0</td></tr><tr><td>4</td><td>158</td><td>78</td><td>0</td><td>0</td><td>32.9</td><td>0.8029999999999999</td><td>31</td><td>1</td></tr><tr><td>2</td><td>127</td><td>58</td><td>24</td><td>275</td><td>27.7</td><td>1.6</td><td>25</td><td>0</td></tr><tr><td>3</td><td>96</td><td>56</td><td>34</td><td>115</td><td>24.7</td><td>0.9440000000000001</td><td>39</td><td>0</td></tr><tr><td>0</td><td>131</td><td>66</td><td>40</td><td>0</td><td>34.3</td><td>0.196</td><td>22</td><td>1</td></tr><tr><td>3</td><td>82</td><td>70</td><td>0</td><td>0</td><td>21.1</td><td>0.389</td><td>25</td><td>0</td></tr><tr><td>3</td><td>193</td><td>70</td><td>31</td><td>0</td><td>34.9</td><td>0.24100000000000002</td><td>25</td><td>1</td></tr><tr><td>4</td><td>95</td><td>64</td><td>0</td><td>0</td><td>32.0</td><td>0.161</td><td>31</td><td>1</td></tr><tr><td>6</td><td>137</td><td>61</td><td>0</td><td>0</td><td>24.2</td><td>0.151</td><td>55</td><td>0</td></tr><tr><td>5</td><td>136</td><td>84</td><td>41</td><td>88</td><td>35.0</td><td>0.28600000000000003</td><td>35</td><td>1</td></tr><tr><td>9</td><td>72</td><td>78</td><td>25</td><td>0</td><td>31.6</td><td>0.28</td><td>38</td><td>0</td></tr><tr><td>5</td><td>168</td><td>64</td><td>0</td><td>0</td><td>32.9</td><td>0.135</td><td>41</td><td>1</td></tr><tr><td>2</td><td>123</td><td>48</td><td>32</td><td>165</td><td>42.1</td><td>0.52</td><td>26</td><td>0</td></tr><tr><td>4</td><td>115</td><td>72</td><td>0</td><td>0</td><td>28.9</td><td>0.376</td><td>46</td><td>1</td></tr><tr><td>0</td><td>101</td><td>62</td><td>0</td><td>0</td><td>21.9</td><td>0.336</td><td>25</td><td>0</td></tr><tr><td>8</td><td>197</td><td>74</td><td>0</td><td>0</td><td>25.9</td><td>1.1909999999999998</td><td>39</td><td>1</td></tr><tr><td>1</td><td>172</td><td>68</td><td>49</td><td>579</td><td>42.4</td><td>0.7020000000000001</td><td>28</td><td>1</td></tr><tr><td>6</td><td>102</td><td>90</td><td>39</td><td>0</td><td>35.7</td><td>0.674</td><td>28</td><td>0</td></tr><tr><td>1</td><td>112</td><td>72</td><td>30</td><td>176</td><td>34.4</td><td>0.528</td><td>25</td><td>0</td></tr><tr><td>1</td><td>143</td><td>84</td><td>23</td><td>310</td><td>42.4</td><td>1.0759999999999998</td><td>22</td><td>0</td></tr><tr><td>1</td><td>143</td><td>74</td><td>22</td><td>61</td><td>26.2</td><td>0.256</td><td>21</td><td>0</td></tr><tr><td>0</td><td>138</td><td>60</td><td>35</td><td>167</td><td>34.6</td><td>0.534</td><td>21</td><td>1</td></tr><tr><td>3</td><td>173</td><td>84</td><td>33</td><td>474</td><td>35.7</td><td>0.258</td><td>22</td><td>1</td></tr><tr><td>1</td><td>97</td><td>68</td><td>21</td><td>0</td><td>27.2</td><td>1.095</td><td>22</td><td>0</td></tr><tr><td>4</td><td>144</td><td>82</td><td>32</td><td>0</td><td>38.5</td><td>0.5539999999999999</td><td>37</td><td>1</td></tr><tr><td>1</td><td>83</td><td>68</td><td>0</td><td>0</td><td>18.2</td><td>0.624</td><td>27</td><td>0</td></tr><tr><td>3</td><td>129</td><td>64</td><td>29</td><td>115</td><td>26.4</td><td>0.21899999999999997</td><td>28</td><td>1</td></tr><tr><td>1</td><td>119</td><td>88</td><td>41</td><td>170</td><td>45.3</td><td>0.507</td><td>26</td><td>0</td></tr><tr><td>2</td><td>94</td><td>68</td><td>18</td><td>76</td><td>26.0</td><td>0.561</td><td>21</td><td>0</td></tr><tr><td>0</td><td>102</td><td>64</td><td>46</td><td>78</td><td>40.6</td><td>0.496</td><td>21</td><td>0</td></tr><tr><td>2</td><td>115</td><td>64</td><td>22</td><td>0</td><td>30.8</td><td>0.42100000000000004</td><td>21</td><td>0</td></tr><tr><td>8</td><td>151</td><td>78</td><td>32</td><td>210</td><td>42.9</td><td>0.516</td><td>36</td><td>1</td></tr><tr><td>4</td><td>184</td><td>78</td><td>39</td><td>277</td><td>37.0</td><td>0.264</td><td>31</td><td>1</td></tr><tr><td>0</td><td>94</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.256</td><td>25</td><td>0</td></tr><tr><td>1</td><td>181</td><td>64</td><td>30</td><td>180</td><td>34.1</td><td>0.32799999999999996</td><td>38</td><td>1</td></tr><tr><td>0</td><td>135</td><td>94</td><td>46</td><td>145</td><td>40.6</td><td>0.284</td><td>26</td><td>0</td></tr><tr><td>1</td><td>95</td><td>82</td><td>25</td><td>180</td><td>35.0</td><td>0.233</td><td>43</td><td>1</td></tr><tr><td>2</td><td>99</td><td>0</td><td>0</td><td>0</td><td>22.2</td><td>0.10800000000000001</td><td>23</td><td>0</td></tr><tr><td>3</td><td>89</td><td>74</td><td>16</td><td>85</td><td>30.4</td><td>0.551</td><td>38</td><td>0</td></tr><tr><td>1</td><td>80</td><td>74</td><td>11</td><td>60</td><td>30.0</td><td>0.527</td><td>22</td><td>0</td></tr><tr><td>2</td><td>139</td><td>75</td><td>0</td><td>0</td><td>25.6</td><td>0.16699999999999998</td><td>29</td><td>0</td></tr><tr><td>1</td><td>90</td><td>68</td><td>8</td><td>0</td><td>24.5</td><td>1.138</td><td>36</td><td>0</td></tr><tr><td>0</td><td>141</td><td>0</td><td>0</td><td>0</td><td>42.4</td><td>0.205</td><td>29</td><td>1</td></tr><tr><td>12</td><td>140</td><td>85</td><td>33</td><td>0</td><td>37.4</td><td>0.244</td><td>41</td><td>0</td></tr><tr><td>5</td><td>147</td><td>75</td><td>0</td><td>0</td><td>29.9</td><td>0.434</td><td>28</td><td>0</td></tr><tr><td>1</td><td>97</td><td>70</td><td>15</td><td>0</td><td>18.2</td><td>0.147</td><td>21</td><td>0</td></tr><tr><td>6</td><td>107</td><td>88</td><td>0</td><td>0</td><td>36.8</td><td>0.727</td><td>31</td><td>0</td></tr><tr><td>0</td><td>189</td><td>104</td><td>25</td><td>0</td><td>34.3</td><td>0.435</td><td>41</td><td>1</td></tr><tr><td>2</td><td>83</td><td>66</td><td>23</td><td>50</td><td>32.2</td><td>0.49700000000000005</td><td>22</td><td>0</td></tr><tr><td>4</td><td>117</td><td>64</td><td>27</td><td>120</td><td>33.2</td><td>0.23</td><td>24</td><td>0</td></tr><tr><td>8</td><td>108</td><td>70</td><td>0</td><td>0</td><td>30.5</td><td>0.955</td><td>33</td><td>1</td></tr><tr><td>4</td><td>117</td><td>62</td><td>12</td><td>0</td><td>29.7</td><td>0.38</td><td>30</td><td>1</td></tr><tr><td>0</td><td>180</td><td>78</td><td>63</td><td>14</td><td>59.4</td><td>2.42</td><td>25</td><td>1</td></tr><tr><td>1</td><td>100</td><td>72</td><td>12</td><td>70</td><td>25.3</td><td>0.6579999999999999</td><td>28</td><td>0</td></tr><tr><td>0</td><td>95</td><td>80</td><td>45</td><td>92</td><td>36.5</td><td>0.33</td><td>26</td><td>0</td></tr><tr><td>0</td><td>104</td><td>64</td><td>37</td><td>64</td><td>33.6</td><td>0.51</td><td>22</td><td>1</td></tr><tr><td>0</td><td>120</td><td>74</td><td>18</td><td>63</td><td>30.5</td><td>0.285</td><td>26</td><td>0</td></tr><tr><td>1</td><td>82</td><td>64</td><td>13</td><td>95</td><td>21.2</td><td>0.415</td><td>23</td><td>0</td></tr><tr><td>2</td><td>134</td><td>70</td><td>0</td><td>0</td><td>28.9</td><td>0.542</td><td>23</td><td>1</td></tr><tr><td>0</td><td>91</td><td>68</td><td>32</td><td>210</td><td>39.9</td><td>0.381</td><td>25</td><td>0</td></tr><tr><td>2</td><td>119</td><td>0</td><td>0</td><td>0</td><td>19.6</td><td>0.8320000000000001</td><td>72</td><td>0</td></tr><tr><td>2</td><td>100</td><td>54</td><td>28</td><td>105</td><td>37.8</td><td>0.498</td><td>24</td><td>0</td></tr><tr><td>14</td><td>175</td><td>62</td><td>30</td><td>0</td><td>33.6</td><td>0.212</td><td>38</td><td>1</td></tr><tr><td>1</td><td>135</td><td>54</td><td>0</td><td>0</td><td>26.7</td><td>0.687</td><td>62</td><td>0</td></tr><tr><td>5</td><td>86</td><td>68</td><td>28</td><td>71</td><td>30.2</td><td>0.364</td><td>24</td><td>0</td></tr><tr><td>10</td><td>148</td><td>84</td><td>48</td><td>237</td><td>37.6</td><td>1.001</td><td>51</td><td>1</td></tr><tr><td>9</td><td>134</td><td>74</td><td>33</td><td>60</td><td>25.9</td><td>0.46</td><td>81</td><td>0</td></tr><tr><td>9</td><td>120</td><td>72</td><td>22</td><td>56</td><td>20.8</td><td>0.733</td><td>48</td><td>0</td></tr><tr><td>1</td><td>71</td><td>62</td><td>0</td><td>0</td><td>21.8</td><td>0.41600000000000004</td><td>26</td><td>0</td></tr><tr><td>8</td><td>74</td><td>70</td><td>40</td><td>49</td><td>35.3</td><td>0.705</td><td>39</td><td>0</td></tr><tr><td>5</td><td>88</td><td>78</td><td>30</td><td>0</td><td>27.6</td><td>0.258</td><td>37</td><td>0</td></tr><tr><td>10</td><td>115</td><td>98</td><td>0</td><td>0</td><td>24.0</td><td>1.022</td><td>34</td><td>0</td></tr><tr><td>0</td><td>124</td><td>56</td><td>13</td><td>105</td><td>21.8</td><td>0.452</td><td>21</td><td>0</td></tr><tr><td>0</td><td>74</td><td>52</td><td>10</td><td>36</td><td>27.8</td><td>0.26899999999999996</td><td>22</td><td>0</td></tr><tr><td>0</td><td>97</td><td>64</td><td>36</td><td>100</td><td>36.8</td><td>0.6</td><td>25</td><td>0</td></tr><tr><td>8</td><td>120</td><td>0</td><td>0</td><td>0</td><td>30.0</td><td>0.183</td><td>38</td><td>1</td></tr><tr><td>6</td><td>154</td><td>78</td><td>41</td><td>140</td><td>46.1</td><td>0.5710000000000001</td><td>27</td><td>0</td></tr><tr><td>1</td><td>144</td><td>82</td><td>40</td><td>0</td><td>41.3</td><td>0.607</td><td>28</td><td>0</td></tr><tr><td>0</td><td>137</td><td>70</td><td>38</td><td>0</td><td>33.2</td><td>0.17</td><td>22</td><td>0</td></tr><tr><td>0</td><td>119</td><td>66</td><td>27</td><td>0</td><td>38.8</td><td>0.259</td><td>22</td><td>0</td></tr><tr><td>7</td><td>136</td><td>90</td><td>0</td><td>0</td><td>29.9</td><td>0.21</td><td>50</td><td>0</td></tr><tr><td>4</td><td>114</td><td>64</td><td>0</td><td>0</td><td>28.9</td><td>0.126</td><td>24</td><td>0</td></tr><tr><td>0</td><td>137</td><td>84</td><td>27</td><td>0</td><td>27.3</td><td>0.231</td><td>59</td><td>0</td></tr><tr><td>2</td><td>105</td><td>80</td><td>45</td><td>191</td><td>33.7</td><td>0.711</td><td>29</td><td>1</td></tr><tr><td>7</td><td>114</td><td>76</td><td>17</td><td>110</td><td>23.8</td><td>0.466</td><td>31</td><td>0</td></tr><tr><td>8</td><td>126</td><td>74</td><td>38</td><td>75</td><td>25.9</td><td>0.162</td><td>39</td><td>0</td></tr><tr><td>4</td><td>132</td><td>86</td><td>31</td><td>0</td><td>28.0</td><td>0.419</td><td>63</td><td>0</td></tr><tr><td>3</td><td>158</td><td>70</td><td>30</td><td>328</td><td>35.5</td><td>0.344</td><td>35</td><td>1</td></tr><tr><td>0</td><td>123</td><td>88</td><td>37</td><td>0</td><td>35.2</td><td>0.19699999999999998</td><td>29</td><td>0</td></tr><tr><td>4</td><td>85</td><td>58</td><td>22</td><td>49</td><td>27.8</td><td>0.306</td><td>28</td><td>0</td></tr><tr><td>0</td><td>84</td><td>82</td><td>31</td><td>125</td><td>38.2</td><td>0.233</td><td>23</td><td>0</td></tr><tr><td>0</td><td>145</td><td>0</td><td>0</td><td>0</td><td>44.2</td><td>0.63</td><td>31</td><td>1</td></tr><tr><td>0</td><td>135</td><td>68</td><td>42</td><td>250</td><td>42.3</td><td>0.365</td><td>24</td><td>1</td></tr><tr><td>1</td><td>139</td><td>62</td><td>41</td><td>480</td><td>40.7</td><td>0.536</td><td>21</td><td>0</td></tr><tr><td>0</td><td>173</td><td>78</td><td>32</td><td>265</td><td>46.5</td><td>1.159</td><td>58</td><td>0</td></tr><tr><td>4</td><td>99</td><td>72</td><td>17</td><td>0</td><td>25.6</td><td>0.294</td><td>28</td><td>0</td></tr><tr><td>8</td><td>194</td><td>80</td><td>0</td><td>0</td><td>26.1</td><td>0.551</td><td>67</td><td>0</td></tr><tr><td>2</td><td>83</td><td>65</td><td>28</td><td>66</td><td>36.8</td><td>0.629</td><td>24</td><td>0</td></tr><tr><td>2</td><td>89</td><td>90</td><td>30</td><td>0</td><td>33.5</td><td>0.292</td><td>42</td><td>0</td></tr><tr><td>4</td><td>99</td><td>68</td><td>38</td><td>0</td><td>32.8</td><td>0.145</td><td>33</td><td>0</td></tr><tr><td>4</td><td>125</td><td>70</td><td>18</td><td>122</td><td>28.9</td><td>1.1440000000000001</td><td>45</td><td>1</td></tr><tr><td>3</td><td>80</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.174</td><td>22</td><td>0</td></tr><tr><td>6</td><td>166</td><td>74</td><td>0</td><td>0</td><td>26.6</td><td>0.304</td><td>66</td><td>0</td></tr><tr><td>5</td><td>110</td><td>68</td><td>0</td><td>0</td><td>26.0</td><td>0.292</td><td>30</td><td>0</td></tr><tr><td>2</td><td>81</td><td>72</td><td>15</td><td>76</td><td>30.1</td><td>0.547</td><td>25</td><td>0</td></tr><tr><td>7</td><td>195</td><td>70</td><td>33</td><td>145</td><td>25.1</td><td>0.163</td><td>55</td><td>1</td></tr><tr><td>6</td><td>154</td><td>74</td><td>32</td><td>193</td><td>29.3</td><td>0.8390000000000001</td><td>39</td><td>0</td></tr><tr><td>2</td><td>117</td><td>90</td><td>19</td><td>71</td><td>25.2</td><td>0.313</td><td>21</td><td>0</td></tr><tr><td>3</td><td>84</td><td>72</td><td>32</td><td>0</td><td>37.2</td><td>0.267</td><td>28</td><td>0</td></tr><tr><td>6</td><td>0</td><td>68</td><td>41</td><td>0</td><td>39.0</td><td>0.727</td><td>41</td><td>1</td></tr><tr><td>7</td><td>94</td><td>64</td><td>25</td><td>79</td><td>33.3</td><td>0.738</td><td>41</td><td>0</td></tr><tr><td>3</td><td>96</td><td>78</td><td>39</td><td>0</td><td>37.3</td><td>0.23800000000000002</td><td>40</td><td>0</td></tr><tr><td>10</td><td>75</td><td>82</td><td>0</td><td>0</td><td>33.3</td><td>0.263</td><td>38</td><td>0</td></tr><tr><td>0</td><td>180</td><td>90</td><td>26</td><td>90</td><td>36.5</td><td>0.314</td><td>35</td><td>1</td></tr><tr><td>1</td><td>130</td><td>60</td><td>23</td><td>170</td><td>28.6</td><td>0.6920000000000001</td><td>21</td><td>0</td></tr><tr><td>2</td><td>84</td><td>50</td><td>23</td><td>76</td><td>30.4</td><td>0.968</td><td>21</td><td>0</td></tr><tr><td>8</td><td>120</td><td>78</td><td>0</td><td>0</td><td>25.0</td><td>0.409</td><td>64</td><td>0</td></tr><tr><td>12</td><td>84</td><td>72</td><td>31</td><td>0</td><td>29.7</td><td>0.297</td><td>46</td><td>1</td></tr><tr><td>0</td><td>139</td><td>62</td><td>17</td><td>210</td><td>22.1</td><td>0.207</td><td>21</td><td>0</td></tr><tr><td>9</td><td>91</td><td>68</td><td>0</td><td>0</td><td>24.2</td><td>0.2</td><td>58</td><td>0</td></tr><tr><td>2</td><td>91</td><td>62</td><td>0</td><td>0</td><td>27.3</td><td>0.525</td><td>22</td><td>0</td></tr><tr><td>3</td><td>99</td><td>54</td><td>19</td><td>86</td><td>25.6</td><td>0.154</td><td>24</td><td>0</td></tr><tr><td>3</td><td>163</td><td>70</td><td>18</td><td>105</td><td>31.6</td><td>0.268</td><td>28</td><td>1</td></tr><tr><td>9</td><td>145</td><td>88</td><td>34</td><td>165</td><td>30.3</td><td>0.7709999999999999</td><td>53</td><td>1</td></tr><tr><td>7</td><td>125</td><td>86</td><td>0</td><td>0</td><td>37.6</td><td>0.304</td><td>51</td><td>0</td></tr><tr><td>13</td><td>76</td><td>60</td><td>0</td><td>0</td><td>32.8</td><td>0.18</td><td>41</td><td>0</td></tr><tr><td>6</td><td>129</td><td>90</td><td>7</td><td>326</td><td>19.6</td><td>0.5820000000000001</td><td>60</td><td>0</td></tr><tr><td>2</td><td>68</td><td>70</td><td>32</td><td>66</td><td>25.0</td><td>0.187</td><td>25</td><td>0</td></tr><tr><td>3</td><td>124</td><td>80</td><td>33</td><td>130</td><td>33.2</td><td>0.305</td><td>26</td><td>0</td></tr><tr><td>6</td><td>114</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.18899999999999997</td><td>26</td><td>0</td></tr><tr><td>9</td><td>130</td><td>70</td><td>0</td><td>0</td><td>34.2</td><td>0.652</td><td>45</td><td>1</td></tr><tr><td>3</td><td>125</td><td>58</td><td>0</td><td>0</td><td>31.6</td><td>0.151</td><td>24</td><td>0</td></tr><tr><td>3</td><td>87</td><td>60</td><td>18</td><td>0</td><td>21.8</td><td>0.444</td><td>21</td><td>0</td></tr><tr><td>1</td><td>97</td><td>64</td><td>19</td><td>82</td><td>18.2</td><td>0.299</td><td>21</td><td>0</td></tr><tr><td>3</td><td>116</td><td>74</td><td>15</td><td>105</td><td>26.3</td><td>0.107</td><td>24</td><td>0</td></tr><tr><td>0</td><td>117</td><td>66</td><td>31</td><td>188</td><td>30.8</td><td>0.493</td><td>22</td><td>0</td></tr><tr><td>0</td><td>111</td><td>65</td><td>0</td><td>0</td><td>24.6</td><td>0.66</td><td>31</td><td>0</td></tr><tr><td>2</td><td>122</td><td>60</td><td>18</td><td>106</td><td>29.8</td><td>0.7170000000000001</td><td>22</td><td>0</td></tr><tr><td>0</td><td>107</td><td>76</td><td>0</td><td>0</td><td>45.3</td><td>0.6859999999999999</td><td>24</td><td>0</td></tr><tr><td>1</td><td>86</td><td>66</td><td>52</td><td>65</td><td>41.3</td><td>0.917</td><td>29</td><td>0</td></tr><tr><td>6</td><td>91</td><td>0</td><td>0</td><td>0</td><td>29.8</td><td>0.501</td><td>31</td><td>0</td></tr><tr><td>1</td><td>77</td><td>56</td><td>30</td><td>56</td><td>33.3</td><td>1.251</td><td>24</td><td>0</td></tr><tr><td>4</td><td>132</td><td>0</td><td>0</td><td>0</td><td>32.9</td><td>0.302</td><td>23</td><td>1</td></tr><tr><td>0</td><td>105</td><td>90</td><td>0</td><td>0</td><td>29.6</td><td>0.19699999999999998</td><td>46</td><td>0</td></tr><tr><td>0</td><td>57</td><td>60</td><td>0</td><td>0</td><td>21.7</td><td>0.735</td><td>67</td><td>0</td></tr><tr><td>0</td><td>127</td><td>80</td><td>37</td><td>210</td><td>36.3</td><td>0.804</td><td>23</td><td>0</td></tr><tr><td>3</td><td>129</td><td>92</td><td>49</td><td>155</td><td>36.4</td><td>0.968</td><td>32</td><td>1</td></tr><tr><td>8</td><td>100</td><td>74</td><td>40</td><td>215</td><td>39.4</td><td>0.6609999999999999</td><td>43</td><td>1</td></tr><tr><td>3</td><td>128</td><td>72</td><td>25</td><td>190</td><td>32.4</td><td>0.5489999999999999</td><td>27</td><td>1</td></tr><tr><td>10</td><td>90</td><td>85</td><td>32</td><td>0</td><td>34.9</td><td>0.825</td><td>56</td><td>1</td></tr><tr><td>4</td><td>84</td><td>90</td><td>23</td><td>56</td><td>39.5</td><td>0.159</td><td>25</td><td>0</td></tr><tr><td>1</td><td>88</td><td>78</td><td>29</td><td>76</td><td>32.0</td><td>0.365</td><td>29</td><td>0</td></tr><tr><td>8</td><td>186</td><td>90</td><td>35</td><td>225</td><td>34.5</td><td>0.423</td><td>37</td><td>1</td></tr><tr><td>5</td><td>187</td><td>76</td><td>27</td><td>207</td><td>43.6</td><td>1.034</td><td>53</td><td>1</td></tr><tr><td>4</td><td>131</td><td>68</td><td>21</td><td>166</td><td>33.1</td><td>0.16</td><td>28</td><td>0</td></tr><tr><td>1</td><td>164</td><td>82</td><td>43</td><td>67</td><td>32.8</td><td>0.341</td><td>50</td><td>0</td></tr><tr><td>4</td><td>189</td><td>110</td><td>31</td><td>0</td><td>28.5</td><td>0.68</td><td>37</td><td>0</td></tr><tr><td>1</td><td>116</td><td>70</td><td>28</td><td>0</td><td>27.4</td><td>0.204</td><td>21</td><td>0</td></tr><tr><td>3</td><td>84</td><td>68</td><td>30</td><td>106</td><td>31.9</td><td>0.591</td><td>25</td><td>0</td></tr><tr><td>6</td><td>114</td><td>88</td><td>0</td><td>0</td><td>27.8</td><td>0.247</td><td>66</td><td>0</td></tr><tr><td>1</td><td>88</td><td>62</td><td>24</td><td>44</td><td>29.9</td><td>0.42200000000000004</td><td>23</td><td>0</td></tr><tr><td>1</td><td>84</td><td>64</td><td>23</td><td>115</td><td>36.9</td><td>0.47100000000000003</td><td>28</td><td>0</td></tr><tr><td>7</td><td>124</td><td>70</td><td>33</td><td>215</td><td>25.5</td><td>0.161</td><td>37</td><td>0</td></tr><tr><td>1</td><td>97</td><td>70</td><td>40</td><td>0</td><td>38.1</td><td>0.218</td><td>30</td><td>0</td></tr><tr><td>8</td><td>110</td><td>76</td><td>0</td><td>0</td><td>27.8</td><td>0.237</td><td>58</td><td>0</td></tr><tr><td>11</td><td>103</td><td>68</td><td>40</td><td>0</td><td>46.2</td><td>0.126</td><td>42</td><td>0</td></tr><tr><td>11</td><td>85</td><td>74</td><td>0</td><td>0</td><td>30.1</td><td>0.3</td><td>35</td><td>0</td></tr><tr><td>6</td><td>125</td><td>76</td><td>0</td><td>0</td><td>33.8</td><td>0.121</td><td>54</td><td>1</td></tr><tr><td>0</td><td>198</td><td>66</td><td>32</td><td>274</td><td>41.3</td><td>0.502</td><td>28</td><td>1</td></tr><tr><td>1</td><td>87</td><td>68</td><td>34</td><td>77</td><td>37.6</td><td>0.401</td><td>24</td><td>0</td></tr><tr><td>6</td><td>99</td><td>60</td><td>19</td><td>54</td><td>26.9</td><td>0.49700000000000005</td><td>32</td><td>0</td></tr><tr><td>0</td><td>91</td><td>80</td><td>0</td><td>0</td><td>32.4</td><td>0.601</td><td>27</td><td>0</td></tr><tr><td>2</td><td>95</td><td>54</td><td>14</td><td>88</td><td>26.1</td><td>0.748</td><td>22</td><td>0</td></tr><tr><td>1</td><td>99</td><td>72</td><td>30</td><td>18</td><td>38.6</td><td>0.41200000000000003</td><td>21</td><td>0</td></tr><tr><td>6</td><td>92</td><td>62</td><td>32</td><td>126</td><td>32.0</td><td>0.085</td><td>46</td><td>0</td></tr><tr><td>4</td><td>154</td><td>72</td><td>29</td><td>126</td><td>31.3</td><td>0.33799999999999997</td><td>37</td><td>0</td></tr><tr><td>0</td><td>121</td><td>66</td><td>30</td><td>165</td><td>34.3</td><td>0.203</td><td>33</td><td>1</td></tr><tr><td>3</td><td>78</td><td>70</td><td>0</td><td>0</td><td>32.5</td><td>0.27</td><td>39</td><td>0</td></tr><tr><td>2</td><td>130</td><td>96</td><td>0</td><td>0</td><td>22.6</td><td>0.268</td><td>21</td><td>0</td></tr><tr><td>3</td><td>111</td><td>58</td><td>31</td><td>44</td><td>29.5</td><td>0.43</td><td>22</td><td>0</td></tr><tr><td>2</td><td>98</td><td>60</td><td>17</td><td>120</td><td>34.7</td><td>0.198</td><td>22</td><td>0</td></tr><tr><td>1</td><td>143</td><td>86</td><td>30</td><td>330</td><td>30.1</td><td>0.892</td><td>23</td><td>0</td></tr><tr><td>1</td><td>119</td><td>44</td><td>47</td><td>63</td><td>35.5</td><td>0.28</td><td>25</td><td>0</td></tr><tr><td>6</td><td>108</td><td>44</td><td>20</td><td>130</td><td>24.0</td><td>0.813</td><td>35</td><td>0</td></tr><tr><td>2</td><td>118</td><td>80</td><td>0</td><td>0</td><td>42.9</td><td>0.693</td><td>21</td><td>1</td></tr><tr><td>10</td><td>133</td><td>68</td><td>0</td><td>0</td><td>27.0</td><td>0.245</td><td>36</td><td>0</td></tr><tr><td>2</td><td>197</td><td>70</td><td>99</td><td>0</td><td>34.7</td><td>0.575</td><td>62</td><td>1</td></tr><tr><td>0</td><td>151</td><td>90</td><td>46</td><td>0</td><td>42.1</td><td>0.371</td><td>21</td><td>1</td></tr><tr><td>6</td><td>109</td><td>60</td><td>27</td><td>0</td><td>25.0</td><td>0.20600000000000002</td><td>27</td><td>0</td></tr><tr><td>12</td><td>121</td><td>78</td><td>17</td><td>0</td><td>26.5</td><td>0.259</td><td>62</td><td>0</td></tr><tr><td>8</td><td>100</td><td>76</td><td>0</td><td>0</td><td>38.7</td><td>0.19</td><td>42</td><td>0</td></tr><tr><td>8</td><td>124</td><td>76</td><td>24</td><td>600</td><td>28.7</td><td>0.687</td><td>52</td><td>1</td></tr><tr><td>1</td><td>93</td><td>56</td><td>11</td><td>0</td><td>22.5</td><td>0.41700000000000004</td><td>22</td><td>0</td></tr><tr><td>8</td><td>143</td><td>66</td><td>0</td><td>0</td><td>34.9</td><td>0.129</td><td>41</td><td>1</td></tr><tr><td>6</td><td>103</td><td>66</td><td>0</td><td>0</td><td>24.3</td><td>0.249</td><td>29</td><td>0</td></tr><tr><td>3</td><td>176</td><td>86</td><td>27</td><td>156</td><td>33.3</td><td>1.1540000000000001</td><td>52</td><td>1</td></tr><tr><td>0</td><td>73</td><td>0</td><td>0</td><td>0</td><td>21.1</td><td>0.342</td><td>25</td><td>0</td></tr><tr><td>11</td><td>111</td><td>84</td><td>40</td><td>0</td><td>46.8</td><td>0.925</td><td>45</td><td>1</td></tr><tr><td>2</td><td>112</td><td>78</td><td>50</td><td>140</td><td>39.4</td><td>0.175</td><td>24</td><td>0</td></tr><tr><td>3</td><td>132</td><td>80</td><td>0</td><td>0</td><td>34.4</td><td>0.402</td><td>44</td><td>1</td></tr><tr><td>2</td><td>82</td><td>52</td><td>22</td><td>115</td><td>28.5</td><td>1.699</td><td>25</td><td>0</td></tr><tr><td>6</td><td>123</td><td>72</td><td>45</td><td>230</td><td>33.6</td><td>0.733</td><td>34</td><td>0</td></tr><tr><td>0</td><td>188</td><td>82</td><td>14</td><td>185</td><td>32.0</td><td>0.682</td><td>22</td><td>1</td></tr><tr><td>0</td><td>67</td><td>76</td><td>0</td><td>0</td><td>45.3</td><td>0.19399999999999998</td><td>46</td><td>0</td></tr><tr><td>1</td><td>89</td><td>24</td><td>19</td><td>25</td><td>27.8</td><td>0.5589999999999999</td><td>21</td><td>0</td></tr><tr><td>1</td><td>173</td><td>74</td><td>0</td><td>0</td><td>36.8</td><td>0.08800000000000001</td><td>38</td><td>1</td></tr><tr><td>1</td><td>109</td><td>38</td><td>18</td><td>120</td><td>23.1</td><td>0.40700000000000003</td><td>26</td><td>0</td></tr><tr><td>1</td><td>108</td><td>88</td><td>19</td><td>0</td><td>27.1</td><td>0.4</td><td>24</td><td>0</td></tr><tr><td>6</td><td>96</td><td>0</td><td>0</td><td>0</td><td>23.7</td><td>0.19</td><td>28</td><td>0</td></tr><tr><td>1</td><td>124</td><td>74</td><td>36</td><td>0</td><td>27.8</td><td>0.1</td><td>30</td><td>0</td></tr><tr><td>7</td><td>150</td><td>78</td><td>29</td><td>126</td><td>35.2</td><td>0.6920000000000001</td><td>54</td><td>1</td></tr><tr><td>4</td><td>183</td><td>0</td><td>0</td><td>0</td><td>28.4</td><td>0.212</td><td>36</td><td>1</td></tr><tr><td>1</td><td>124</td><td>60</td><td>32</td><td>0</td><td>35.8</td><td>0.514</td><td>21</td><td>0</td></tr><tr><td>1</td><td>181</td><td>78</td><td>42</td><td>293</td><td>40.0</td><td>1.258</td><td>22</td><td>1</td></tr><tr><td>1</td><td>92</td><td>62</td><td>25</td><td>41</td><td>19.5</td><td>0.48200000000000004</td><td>25</td><td>0</td></tr><tr><td>0</td><td>152</td><td>82</td><td>39</td><td>272</td><td>41.5</td><td>0.27</td><td>27</td><td>0</td></tr><tr><td>1</td><td>111</td><td>62</td><td>13</td><td>182</td><td>24.0</td><td>0.138</td><td>23</td><td>0</td></tr><tr><td>3</td><td>106</td><td>54</td><td>21</td><td>158</td><td>30.9</td><td>0.292</td><td>24</td><td>0</td></tr><tr><td>3</td><td>174</td><td>58</td><td>22</td><td>194</td><td>32.9</td><td>0.593</td><td>36</td><td>1</td></tr><tr><td>7</td><td>168</td><td>88</td><td>42</td><td>321</td><td>38.2</td><td>0.787</td><td>40</td><td>1</td></tr><tr><td>6</td><td>105</td><td>80</td><td>28</td><td>0</td><td>32.5</td><td>0.878</td><td>26</td><td>0</td></tr><tr><td>11</td><td>138</td><td>74</td><td>26</td><td>144</td><td>36.1</td><td>0.557</td><td>50</td><td>1</td></tr><tr><td>3</td><td>106</td><td>72</td><td>0</td><td>0</td><td>25.8</td><td>0.207</td><td>27</td><td>0</td></tr><tr><td>6</td><td>117</td><td>96</td><td>0</td><td>0</td><td>28.7</td><td>0.157</td><td>30</td><td>0</td></tr><tr><td>2</td><td>68</td><td>62</td><td>13</td><td>15</td><td>20.1</td><td>0.257</td><td>23</td><td>0</td></tr><tr><td>9</td><td>112</td><td>82</td><td>24</td><td>0</td><td>28.2</td><td>1.2819999999999998</td><td>50</td><td>1</td></tr><tr><td>0</td><td>119</td><td>0</td><td>0</td><td>0</td><td>32.4</td><td>0.141</td><td>24</td><td>1</td></tr><tr><td>2</td><td>112</td><td>86</td><td>42</td><td>160</td><td>38.4</td><td>0.24600000000000002</td><td>28</td><td>0</td></tr><tr><td>2</td><td>92</td><td>76</td><td>20</td><td>0</td><td>24.2</td><td>1.6980000000000002</td><td>28</td><td>0</td></tr><tr><td>6</td><td>183</td><td>94</td><td>0</td><td>0</td><td>40.8</td><td>1.4609999999999999</td><td>45</td><td>0</td></tr><tr><td>0</td><td>94</td><td>70</td><td>27</td><td>115</td><td>43.5</td><td>0.34700000000000003</td><td>21</td><td>0</td></tr><tr><td>2</td><td>108</td><td>64</td><td>0</td><td>0</td><td>30.8</td><td>0.158</td><td>21</td><td>0</td></tr><tr><td>4</td><td>90</td><td>88</td><td>47</td><td>54</td><td>37.7</td><td>0.36200000000000004</td><td>29</td><td>0</td></tr><tr><td>0</td><td>125</td><td>68</td><td>0</td><td>0</td><td>24.7</td><td>0.20600000000000002</td><td>21</td><td>0</td></tr><tr><td>0</td><td>132</td><td>78</td><td>0</td><td>0</td><td>32.4</td><td>0.39299999999999996</td><td>21</td><td>0</td></tr><tr><td>5</td><td>128</td><td>80</td><td>0</td><td>0</td><td>34.6</td><td>0.14400000000000002</td><td>45</td><td>0</td></tr><tr><td>4</td><td>94</td><td>65</td><td>22</td><td>0</td><td>24.7</td><td>0.14800000000000002</td><td>21</td><td>0</td></tr><tr><td>7</td><td>114</td><td>64</td><td>0</td><td>0</td><td>27.4</td><td>0.732</td><td>34</td><td>1</td></tr><tr><td>0</td><td>102</td><td>78</td><td>40</td><td>90</td><td>34.5</td><td>0.23800000000000002</td><td>24</td><td>0</td></tr><tr><td>2</td><td>111</td><td>60</td><td>0</td><td>0</td><td>26.2</td><td>0.34299999999999997</td><td>23</td><td>0</td></tr><tr><td>1</td><td>128</td><td>82</td><td>17</td><td>183</td><td>27.5</td><td>0.115</td><td>22</td><td>0</td></tr><tr><td>10</td><td>92</td><td>62</td><td>0</td><td>0</td><td>25.9</td><td>0.16699999999999998</td><td>31</td><td>0</td></tr><tr><td>13</td><td>104</td><td>72</td><td>0</td><td>0</td><td>31.2</td><td>0.465</td><td>38</td><td>1</td></tr><tr><td>5</td><td>104</td><td>74</td><td>0</td><td>0</td><td>28.8</td><td>0.153</td><td>48</td><td>0</td></tr><tr><td>2</td><td>94</td><td>76</td><td>18</td><td>66</td><td>31.6</td><td>0.649</td><td>23</td><td>0</td></tr><tr><td>7</td><td>97</td><td>76</td><td>32</td><td>91</td><td>40.9</td><td>0.871</td><td>32</td><td>1</td></tr><tr><td>1</td><td>100</td><td>74</td><td>12</td><td>46</td><td>19.5</td><td>0.149</td><td>28</td><td>0</td></tr><tr><td>0</td><td>102</td><td>86</td><td>17</td><td>105</td><td>29.3</td><td>0.695</td><td>27</td><td>0</td></tr><tr><td>4</td><td>128</td><td>70</td><td>0</td><td>0</td><td>34.3</td><td>0.303</td><td>24</td><td>0</td></tr><tr><td>6</td><td>147</td><td>80</td><td>0</td><td>0</td><td>29.5</td><td>0.17800000000000002</td><td>50</td><td>1</td></tr><tr><td>4</td><td>90</td><td>0</td><td>0</td><td>0</td><td>28.0</td><td>0.61</td><td>31</td><td>0</td></tr><tr><td>3</td><td>103</td><td>72</td><td>30</td><td>152</td><td>27.6</td><td>0.73</td><td>27</td><td>0</td></tr><tr><td>2</td><td>157</td><td>74</td><td>35</td><td>440</td><td>39.4</td><td>0.134</td><td>30</td><td>0</td></tr><tr><td>1</td><td>167</td><td>74</td><td>17</td><td>144</td><td>23.4</td><td>0.447</td><td>33</td><td>1</td></tr><tr><td>0</td><td>179</td><td>50</td><td>36</td><td>159</td><td>37.8</td><td>0.455</td><td>22</td><td>1</td></tr><tr><td>11</td><td>136</td><td>84</td><td>35</td><td>130</td><td>28.3</td><td>0.26</td><td>42</td><td>1</td></tr><tr><td>0</td><td>107</td><td>60</td><td>25</td><td>0</td><td>26.4</td><td>0.133</td><td>23</td><td>0</td></tr><tr><td>1</td><td>91</td><td>54</td><td>25</td><td>100</td><td>25.2</td><td>0.23399999999999999</td><td>23</td><td>0</td></tr><tr><td>1</td><td>117</td><td>60</td><td>23</td><td>106</td><td>33.8</td><td>0.466</td><td>27</td><td>0</td></tr><tr><td>5</td><td>123</td><td>74</td><td>40</td><td>77</td><td>34.1</td><td>0.26899999999999996</td><td>28</td><td>0</td></tr><tr><td>2</td><td>120</td><td>54</td><td>0</td><td>0</td><td>26.8</td><td>0.455</td><td>27</td><td>0</td></tr><tr><td>1</td><td>106</td><td>70</td><td>28</td><td>135</td><td>34.2</td><td>0.142</td><td>22</td><td>0</td></tr><tr><td>2</td><td>155</td><td>52</td><td>27</td><td>540</td><td>38.7</td><td>0.24</td><td>25</td><td>1</td></tr><tr><td>2</td><td>101</td><td>58</td><td>35</td><td>90</td><td>21.8</td><td>0.155</td><td>22</td><td>0</td></tr><tr><td>1</td><td>120</td><td>80</td><td>48</td><td>200</td><td>38.9</td><td>1.162</td><td>41</td><td>0</td></tr><tr><td>11</td><td>127</td><td>106</td><td>0</td><td>0</td><td>39.0</td><td>0.19</td><td>51</td><td>0</td></tr><tr><td>3</td><td>80</td><td>82</td><td>31</td><td>70</td><td>34.2</td><td>1.2919999999999998</td><td>27</td><td>1</td></tr><tr><td>10</td><td>162</td><td>84</td><td>0</td><td>0</td><td>27.7</td><td>0.182</td><td>54</td><td>0</td></tr><tr><td>1</td><td>199</td><td>76</td><td>43</td><td>0</td><td>42.9</td><td>1.3940000000000001</td><td>22</td><td>1</td></tr><tr><td>8</td><td>167</td><td>106</td><td>46</td><td>231</td><td>37.6</td><td>0.165</td><td>43</td><td>1</td></tr><tr><td>9</td><td>145</td><td>80</td><td>46</td><td>130</td><td>37.9</td><td>0.637</td><td>40</td><td>1</td></tr><tr><td>6</td><td>115</td><td>60</td><td>39</td><td>0</td><td>33.7</td><td>0.245</td><td>40</td><td>1</td></tr><tr><td>1</td><td>112</td><td>80</td><td>45</td><td>132</td><td>34.8</td><td>0.217</td><td>24</td><td>0</td></tr><tr><td>4</td><td>145</td><td>82</td><td>18</td><td>0</td><td>32.5</td><td>0.235</td><td>70</td><td>1</td></tr><tr><td>10</td><td>111</td><td>70</td><td>27</td><td>0</td><td>27.5</td><td>0.141</td><td>40</td><td>1</td></tr><tr><td>6</td><td>98</td><td>58</td><td>33</td><td>190</td><td>34.0</td><td>0.43</td><td>43</td><td>0</td></tr><tr><td>9</td><td>154</td><td>78</td><td>30</td><td>100</td><td>30.9</td><td>0.16399999999999998</td><td>45</td><td>0</td></tr><tr><td>6</td><td>165</td><td>68</td><td>26</td><td>168</td><td>33.6</td><td>0.631</td><td>49</td><td>0</td></tr><tr><td>1</td><td>99</td><td>58</td><td>10</td><td>0</td><td>25.4</td><td>0.551</td><td>21</td><td>0</td></tr><tr><td>10</td><td>68</td><td>106</td><td>23</td><td>49</td><td>35.5</td><td>0.285</td><td>47</td><td>0</td></tr><tr><td>3</td><td>123</td><td>100</td><td>35</td><td>240</td><td>57.3</td><td>0.88</td><td>22</td><td>0</td></tr><tr><td>8</td><td>91</td><td>82</td><td>0</td><td>0</td><td>35.6</td><td>0.5870000000000001</td><td>68</td><td>0</td></tr><tr><td>6</td><td>195</td><td>70</td><td>0</td><td>0</td><td>30.9</td><td>0.32799999999999996</td><td>31</td><td>1</td></tr><tr><td>9</td><td>156</td><td>86</td><td>0</td><td>0</td><td>24.8</td><td>0.23</td><td>53</td><td>1</td></tr><tr><td>0</td><td>93</td><td>60</td><td>0</td><td>0</td><td>35.3</td><td>0.263</td><td>25</td><td>0</td></tr><tr><td>3</td><td>121</td><td>52</td><td>0</td><td>0</td><td>36.0</td><td>0.127</td><td>25</td><td>1</td></tr><tr><td>2</td><td>101</td><td>58</td><td>17</td><td>265</td><td>24.2</td><td>0.614</td><td>23</td><td>0</td></tr><tr><td>2</td><td>56</td><td>56</td><td>28</td><td>45</td><td>24.2</td><td>0.332</td><td>22</td><td>0</td></tr><tr><td>0</td><td>162</td><td>76</td><td>36</td><td>0</td><td>49.6</td><td>0.364</td><td>26</td><td>1</td></tr><tr><td>0</td><td>95</td><td>64</td><td>39</td><td>105</td><td>44.6</td><td>0.366</td><td>22</td><td>0</td></tr><tr><td>4</td><td>125</td><td>80</td><td>0</td><td>0</td><td>32.3</td><td>0.536</td><td>27</td><td>1</td></tr><tr><td>5</td><td>136</td><td>82</td><td>0</td><td>0</td><td>0.0</td><td>0.64</td><td>69</td><td>0</td></tr><tr><td>2</td><td>129</td><td>74</td><td>26</td><td>205</td><td>33.2</td><td>0.591</td><td>25</td><td>0</td></tr><tr><td>3</td><td>130</td><td>64</td><td>0</td><td>0</td><td>23.1</td><td>0.314</td><td>22</td><td>0</td></tr><tr><td>1</td><td>107</td><td>50</td><td>19</td><td>0</td><td>28.3</td><td>0.18100000000000002</td><td>29</td><td>0</td></tr><tr><td>1</td><td>140</td><td>74</td><td>26</td><td>180</td><td>24.1</td><td>0.828</td><td>23</td><td>0</td></tr><tr><td>1</td><td>144</td><td>82</td><td>46</td><td>180</td><td>46.1</td><td>0.335</td><td>46</td><td>1</td></tr><tr><td>8</td><td>107</td><td>80</td><td>0</td><td>0</td><td>24.6</td><td>0.856</td><td>34</td><td>0</td></tr><tr><td>13</td><td>158</td><td>114</td><td>0</td><td>0</td><td>42.3</td><td>0.257</td><td>44</td><td>1</td></tr><tr><td>2</td><td>121</td><td>70</td><td>32</td><td>95</td><td>39.1</td><td>0.8859999999999999</td><td>23</td><td>0</td></tr><tr><td>7</td><td>129</td><td>68</td><td>49</td><td>125</td><td>38.5</td><td>0.439</td><td>43</td><td>1</td></tr><tr><td>2</td><td>90</td><td>60</td><td>0</td><td>0</td><td>23.5</td><td>0.191</td><td>25</td><td>0</td></tr><tr><td>7</td><td>142</td><td>90</td><td>24</td><td>480</td><td>30.4</td><td>0.128</td><td>43</td><td>1</td></tr><tr><td>3</td><td>169</td><td>74</td><td>19</td><td>125</td><td>29.9</td><td>0.268</td><td>31</td><td>1</td></tr><tr><td>0</td><td>99</td><td>0</td><td>0</td><td>0</td><td>25.0</td><td>0.253</td><td>22</td><td>0</td></tr><tr><td>4</td><td>127</td><td>88</td><td>11</td><td>155</td><td>34.5</td><td>0.598</td><td>28</td><td>0</td></tr><tr><td>4</td><td>118</td><td>70</td><td>0</td><td>0</td><td>44.5</td><td>0.904</td><td>26</td><td>0</td></tr><tr><td>2</td><td>122</td><td>76</td><td>27</td><td>200</td><td>35.9</td><td>0.483</td><td>26</td><td>0</td></tr><tr><td>6</td><td>125</td><td>78</td><td>31</td><td>0</td><td>27.6</td><td>0.565</td><td>49</td><td>1</td></tr><tr><td>1</td><td>168</td><td>88</td><td>29</td><td>0</td><td>35.0</td><td>0.905</td><td>52</td><td>1</td></tr><tr><td>2</td><td>129</td><td>0</td><td>0</td><td>0</td><td>38.5</td><td>0.304</td><td>41</td><td>0</td></tr><tr><td>4</td><td>110</td><td>76</td><td>20</td><td>100</td><td>28.4</td><td>0.11800000000000001</td><td>27</td><td>0</td></tr><tr><td>6</td><td>80</td><td>80</td><td>36</td><td>0</td><td>39.8</td><td>0.177</td><td>28</td><td>0</td></tr><tr><td>10</td><td>115</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0.261</td><td>30</td><td>1</td></tr><tr><td>2</td><td>127</td><td>46</td><td>21</td><td>335</td><td>34.4</td><td>0.17600000000000002</td><td>22</td><td>0</td></tr><tr><td>9</td><td>164</td><td>78</td><td>0</td><td>0</td><td>32.8</td><td>0.14800000000000002</td><td>45</td><td>1</td></tr><tr><td>2</td><td>93</td><td>64</td><td>32</td><td>160</td><td>38.0</td><td>0.674</td><td>23</td><td>1</td></tr><tr><td>3</td><td>158</td><td>64</td><td>13</td><td>387</td><td>31.2</td><td>0.295</td><td>24</td><td>0</td></tr><tr><td>5</td><td>126</td><td>78</td><td>27</td><td>22</td><td>29.6</td><td>0.439</td><td>40</td><td>0</td></tr><tr><td>10</td><td>129</td><td>62</td><td>36</td><td>0</td><td>41.2</td><td>0.441</td><td>38</td><td>1</td></tr><tr><td>0</td><td>134</td><td>58</td><td>20</td><td>291</td><td>26.4</td><td>0.35200000000000004</td><td>21</td><td>0</td></tr><tr><td>3</td><td>102</td><td>74</td><td>0</td><td>0</td><td>29.5</td><td>0.121</td><td>32</td><td>0</td></tr><tr><td>7</td><td>187</td><td>50</td><td>33</td><td>392</td><td>33.9</td><td>0.826</td><td>34</td><td>1</td></tr><tr><td>3</td><td>173</td><td>78</td><td>39</td><td>185</td><td>33.8</td><td>0.97</td><td>31</td><td>1</td></tr><tr><td>10</td><td>94</td><td>72</td><td>18</td><td>0</td><td>23.1</td><td>0.595</td><td>56</td><td>0</td></tr><tr><td>1</td><td>108</td><td>60</td><td>46</td><td>178</td><td>35.5</td><td>0.415</td><td>24</td><td>0</td></tr><tr><td>5</td><td>97</td><td>76</td><td>27</td><td>0</td><td>35.6</td><td>0.37799999999999995</td><td>52</td><td>1</td></tr><tr><td>4</td><td>83</td><td>86</td><td>19</td><td>0</td><td>29.3</td><td>0.317</td><td>34</td><td>0</td></tr><tr><td>1</td><td>114</td><td>66</td><td>36</td><td>200</td><td>38.1</td><td>0.289</td><td>21</td><td>0</td></tr><tr><td>1</td><td>149</td><td>68</td><td>29</td><td>127</td><td>29.3</td><td>0.349</td><td>42</td><td>1</td></tr><tr><td>5</td><td>117</td><td>86</td><td>30</td><td>105</td><td>39.1</td><td>0.251</td><td>42</td><td>0</td></tr><tr><td>1</td><td>111</td><td>94</td><td>0</td><td>0</td><td>32.8</td><td>0.265</td><td>45</td><td>0</td></tr><tr><td>4</td><td>112</td><td>78</td><td>40</td><td>0</td><td>39.4</td><td>0.23600000000000002</td><td>38</td><td>0</td></tr><tr><td>1</td><td>116</td><td>78</td><td>29</td><td>180</td><td>36.1</td><td>0.496</td><td>25</td><td>0</td></tr><tr><td>0</td><td>141</td><td>84</td><td>26</td><td>0</td><td>32.4</td><td>0.433</td><td>22</td><td>0</td></tr><tr><td>2</td><td>175</td><td>88</td><td>0</td><td>0</td><td>22.9</td><td>0.326</td><td>22</td><td>0</td></tr><tr><td>2</td><td>92</td><td>52</td><td>0</td><td>0</td><td>30.1</td><td>0.141</td><td>22</td><td>0</td></tr><tr><td>3</td><td>130</td><td>78</td><td>23</td><td>79</td><td>28.4</td><td>0.32299999999999995</td><td>34</td><td>1</td></tr><tr><td>8</td><td>120</td><td>86</td><td>0</td><td>0</td><td>28.4</td><td>0.259</td><td>22</td><td>1</td></tr><tr><td>2</td><td>174</td><td>88</td><td>37</td><td>120</td><td>44.5</td><td>0.6459999999999999</td><td>24</td><td>1</td></tr><tr><td>2</td><td>106</td><td>56</td><td>27</td><td>165</td><td>29.0</td><td>0.426</td><td>22</td><td>0</td></tr><tr><td>2</td><td>105</td><td>75</td><td>0</td><td>0</td><td>23.3</td><td>0.56</td><td>53</td><td>0</td></tr><tr><td>4</td><td>95</td><td>60</td><td>32</td><td>0</td><td>35.4</td><td>0.284</td><td>28</td><td>0</td></tr><tr><td>0</td><td>126</td><td>86</td><td>27</td><td>120</td><td>27.4</td><td>0.515</td><td>21</td><td>0</td></tr><tr><td>8</td><td>65</td><td>72</td><td>23</td><td>0</td><td>32.0</td><td>0.6</td><td>42</td><td>0</td></tr><tr><td>2</td><td>99</td><td>60</td><td>17</td><td>160</td><td>36.6</td><td>0.45299999999999996</td><td>21</td><td>0</td></tr><tr><td>1</td><td>102</td><td>74</td><td>0</td><td>0</td><td>39.5</td><td>0.293</td><td>42</td><td>1</td></tr><tr><td>11</td><td>120</td><td>80</td><td>37</td><td>150</td><td>42.3</td><td>0.785</td><td>48</td><td>1</td></tr><tr><td>3</td><td>102</td><td>44</td><td>20</td><td>94</td><td>30.8</td><td>0.4</td><td>26</td><td>0</td></tr><tr><td>1</td><td>109</td><td>58</td><td>18</td><td>116</td><td>28.5</td><td>0.21899999999999997</td><td>22</td><td>0</td></tr><tr><td>9</td><td>140</td><td>94</td><td>0</td><td>0</td><td>32.7</td><td>0.7340000000000001</td><td>45</td><td>1</td></tr><tr><td>13</td><td>153</td><td>88</td><td>37</td><td>140</td><td>40.6</td><td>1.1740000000000002</td><td>39</td><td>0</td></tr><tr><td>12</td><td>100</td><td>84</td><td>33</td><td>105</td><td>30.0</td><td>0.488</td><td>46</td><td>0</td></tr><tr><td>1</td><td>147</td><td>94</td><td>41</td><td>0</td><td>49.3</td><td>0.358</td><td>27</td><td>1</td></tr><tr><td>1</td><td>81</td><td>74</td><td>41</td><td>57</td><td>46.3</td><td>1.0959999999999999</td><td>32</td><td>0</td></tr><tr><td>3</td><td>187</td><td>70</td><td>22</td><td>200</td><td>36.4</td><td>0.408</td><td>36</td><td>1</td></tr><tr><td>6</td><td>162</td><td>62</td><td>0</td><td>0</td><td>24.3</td><td>0.17800000000000002</td><td>50</td><td>1</td></tr><tr><td>4</td><td>136</td><td>70</td><td>0</td><td>0</td><td>31.2</td><td>1.182</td><td>22</td><td>1</td></tr><tr><td>1</td><td>121</td><td>78</td><td>39</td><td>74</td><td>39.0</td><td>0.261</td><td>28</td><td>0</td></tr><tr><td>3</td><td>108</td><td>62</td><td>24</td><td>0</td><td>26.0</td><td>0.223</td><td>25</td><td>0</td></tr><tr><td>0</td><td>181</td><td>88</td><td>44</td><td>510</td><td>43.3</td><td>0.222</td><td>26</td><td>1</td></tr><tr><td>8</td><td>154</td><td>78</td><td>32</td><td>0</td><td>32.4</td><td>0.44299999999999995</td><td>45</td><td>1</td></tr><tr><td>1</td><td>128</td><td>88</td><td>39</td><td>110</td><td>36.5</td><td>1.057</td><td>37</td><td>1</td></tr><tr><td>7</td><td>137</td><td>90</td><td>41</td><td>0</td><td>32.0</td><td>0.391</td><td>39</td><td>0</td></tr><tr><td>0</td><td>123</td><td>72</td><td>0</td><td>0</td><td>36.3</td><td>0.258</td><td>52</td><td>1</td></tr><tr><td>1</td><td>106</td><td>76</td><td>0</td><td>0</td><td>37.5</td><td>0.19699999999999998</td><td>26</td><td>0</td></tr><tr><td>6</td><td>190</td><td>92</td><td>0</td><td>0</td><td>35.5</td><td>0.278</td><td>66</td><td>1</td></tr><tr><td>2</td><td>88</td><td>58</td><td>26</td><td>16</td><td>28.4</td><td>0.7659999999999999</td><td>22</td><td>0</td></tr><tr><td>9</td><td>170</td><td>74</td><td>31</td><td>0</td><td>44.0</td><td>0.40299999999999997</td><td>43</td><td>1</td></tr><tr><td>9</td><td>89</td><td>62</td><td>0</td><td>0</td><td>22.5</td><td>0.142</td><td>33</td><td>0</td></tr><tr><td>10</td><td>101</td><td>76</td><td>48</td><td>180</td><td>32.9</td><td>0.171</td><td>63</td><td>0</td></tr><tr><td>2</td><td>122</td><td>70</td><td>27</td><td>0</td><td>36.8</td><td>0.34</td><td>27</td><td>0</td></tr><tr><td>5</td><td>121</td><td>72</td><td>23</td><td>112</td><td>26.2</td><td>0.245</td><td>30</td><td>0</td></tr><tr><td>1</td><td>126</td><td>60</td><td>0</td><td>0</td><td>30.1</td><td>0.349</td><td>47</td><td>1</td></tr><tr><td>1</td><td>93</td><td>70</td><td>31</td><td>0</td><td>30.4</td><td>0.315</td><td>23</td><td>0</td></tr></tbody></table></div>"]}}],"execution_count":5},{"cell_type":"code","source":["spark_df.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[13]: Row(Pregnancies=6, Glucose=148, BloodPressure=72, SkinThickness=35, Insulin=0, BMI=33.6, DiabetesPedigreeFunction=0.627, Age=50, Outcome=1)</div>"]}}],"execution_count":6},{"cell_type":"code","source":["df.head()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":7},{"cell_type":"markdown","source":["Getting dimension of dataframe"],"metadata":{}},{"cell_type":"code","source":["print(\"dimension of diabetes data: {}\".format(df.shape))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">dimension of diabetes data: (768, 9)\n</div>"]}}],"execution_count":9},{"cell_type":"markdown","source":["Outcome has two values: 0 (No diabete) and 1 (Diabete). We will predict for Outcome. print(diabetes.groupby('Outcome').size())"],"metadata":{}},{"cell_type":"code","source":["print(df.groupby('Outcome').size())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Outcome\n0    500\n1    268\ndtype: int64\n</div>"]}}],"execution_count":11},{"cell_type":"code","source":["import seaborn as sns\nsns.countplot(df['Outcome'],label=\"Count\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: &lt;matplotlib.axes._subplots.AxesSubplot at 0x7ff00a18a9b0&gt;</div>"]}}],"execution_count":12},{"cell_type":"markdown","source":["Calculating proportion of Diabete"],"metadata":{}},{"cell_type":"code","source":["res_target = (spark_df.groupBy(\"Outcome\").\\\n              agg(fn.count('Outcome').alias('Headcounts'),\n            ((fn.count('Outcome')/int(spark_df.count()))*100).alias('Proportions')))\n\nres_target = res_target.withColumn(\"Proportions\", fn.round(res_target[\"Proportions\"], 2))\nres_target.registerTempTable(\"res_target\")\n\ndisplay(sqlContext.sql(\"SELECT * FROM res_target\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>Outcome</th><th>Headcounts</th><th>Proportions</th></tr></thead><tbody><tr><td>0</td><td>500</td><td>65.1</td></tr><tr><td>1</td><td>268</td><td>34.9</td></tr></tbody></table></div>"]}}],"execution_count":14},{"cell_type":"markdown","source":["Plot the proportion of Diabete and Non-diabete"],"metadata":{}},{"cell_type":"code","source":["labels = 'non-diabete', 'diabete'\nsizes = [res_target.toPandas()['Headcounts'][0], res_target.toPandas()['Headcounts'][1]]\ncolors = ['indianred', 'tomato']\nexplode = (0, 0.1) \n \n# Plot\nfig, ax = plt.subplots()\nax = plt.pie(sizes, explode = explode, colors = colors, \n             autopct = '%1.1f%%', shadow = True, startangle = 140)\nplt.axis('equal')\nplt.title('Repartition of the diabete and non-diabete patients')\nplt.legend(labels)\n\ndisplay(fig)"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"code","source":["df.info()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;\nRangeIndex: 768 entries, 0 to 767\nData columns (total 9 columns):\nPregnancies                 768 non-null int64\nGlucose                     768 non-null int64\nBloodPressure               768 non-null int64\nSkinThickness               768 non-null int64\nInsulin                     768 non-null int64\nBMI                         768 non-null float64\nDiabetesPedigreeFunction    768 non-null float64\nAge                         768 non-null int64\nOutcome                     768 non-null int64\ndtypes: float64(2), int64(7)\nmemory usage: 54.1 KB\n</div>"]}}],"execution_count":17},{"cell_type":"markdown","source":["All variables in our data are numeric"],"metadata":{}},{"cell_type":"markdown","source":["##### Preparing for training and test dataset"],"metadata":{}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns != 'Outcome'], df['Outcome'], stratify=df['Outcome'], random_state=66)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":20},{"cell_type":"markdown","source":["# Logistic regression"],"metadata":{}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\nLR = LogisticRegression().fit(X_train, y_train)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["print(\"Training set accuracy: {:.3f}\".format(LR.score(X_train, y_train)))\nprint(\"Test set accuracy: {:.3f}\".format(LR.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Training set accuracy: 0.781\nTest set accuracy: 0.771\n</div>"]}}],"execution_count":23},{"cell_type":"markdown","source":["#### Changing C value to see how the accuracy changC"],"metadata":{}},{"cell_type":"code","source":["LR001 = LogisticRegression(C = 0.01).fit(X_train, y_train)\nprint(\"Training set accuracy: {:.3f}\".format(LR001.score(X_train, y_train)))\nprint(\"Test set accuracy: {:.3f}\".format(LR001.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\nTraining set accuracy: 0.700\nTest set accuracy: 0.703\n</div>"]}}],"execution_count":25},{"cell_type":"code","source":["LR100 = LogisticRegression(C = 100).fit(X_train, y_train)\nprint(\"Training set accuracy: {:.3f}\".format(LR100.score(X_train, y_train)))\nprint(\"Test set accuracy: {:.3f}\".format(LR100.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to &#39;lbfgs&#39; in 0.22. Specify a solver to silence this warning.\n  FutureWarning)\nTraining set accuracy: 0.785\nTest set accuracy: 0.766\n</div>"]}}],"execution_count":26},{"cell_type":"markdown","source":["#### We get that they are not so different when C changes. Thus, we use the default value of C = 1"],"metadata":{}},{"cell_type":"markdown","source":["#### Visualization of coefficients for three regularization C = 1, C = 0.01, C = 100"],"metadata":{}},{"cell_type":"code","source":["diabetes_features = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\nplt.figure(figsize=(8,6))\nplt.plot(LR.coef_.T, 'o', label=\"C=1\")\nplt.plot(LR100.coef_.T, '^', label=\"C=100\")\nplt.plot(LR001.coef_.T, 'v', label=\"C=0.01\")\nplt.xticks(range(df.shape[1]), diabetes_features, rotation=90)\nplt.hlines(0, 0, df.shape[1])\nplt.ylim(-5, 5)\nplt.xlabel(\"Feature\")\nplt.ylabel(\"Coefficient magnitude\")\nplt.legend()\n#plt.savefig('log_coef')\nplt.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"markdown","source":["# Decision tree"],"metadata":{}},{"cell_type":"code","source":["from sklearn.tree import DecisionTreeClassifier\ntree = DecisionTreeClassifier(random_state=0)\ntree.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 1.000\nAccuracy on test set: 0.714\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["The accuracy on the training set is 100%, while the test set accuracy is much worse.\n\nThis is an indicative that the tree is overfitting and not generalizing well to new data. \n\nTherefore, we need to apply pre-pruning to the tree."],"metadata":{}},{"cell_type":"markdown","source":["We set max_depth=3, limiting the depth of the tree decreases overfitting. \n\nThis leads to a lower accuracy on the training set, but an improvement on the test set."],"metadata":{}},{"cell_type":"code","source":["tree = DecisionTreeClassifier(max_depth=3, random_state=0)\ntree.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(tree.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(tree.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 0.773\nAccuracy on test set: 0.740\n</div>"]}}],"execution_count":34},{"cell_type":"markdown","source":["###Feature Importance in Decision Trees\n\nFeature importance shows how important each feature is for the decision a tree makes. It is a number between 0 and 1 for each feature, where 0 means “not used at all” and 1 means “perfectly predicts the target”. The feature importances always sum to 1."],"metadata":{}},{"cell_type":"code","source":["print(\"Feature importances:\\n{}\".format(tree.feature_importances_))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Feature importances:\n[0.04554275 0.6830362  0.         0.         0.         0.27142106\n 0.         0.        ]\n</div>"]}}],"execution_count":36},{"cell_type":"markdown","source":["Glucose is the most important feature"],"metadata":{}},{"cell_type":"code","source":["def plot_feature_importances_diabetes(model):\n    plt.figure(figsize=(8,6))\n    n_features = 8\n    plt.barh(range(n_features), model.feature_importances_, align='center')\n    plt.yticks(np.arange(n_features), diabetes_features)\n    plt.xlabel(\"Feature importance\")\n    plt.ylabel(\"Feature\")\n    plt.ylim(-1, n_features)\n    plot_feature_importances_diabetes(tree)\nplt.savefig('feature_importance') # I do not know where it is saved"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["# Random Forest"],"metadata":{}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100, random_state=0) # we use a random forest consisting of 100 trees\nrf.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(rf.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(rf.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 1.000\nAccuracy on test set: 0.786\n</div>"]}}],"execution_count":40},{"cell_type":"markdown","source":["The random forest gives us an accuracy of 78.6%, better than the logistic regression model or a single decision tree, without tuning any parameters. However, we can adjust the max_features setting, to see whether the result can be improved."],"metadata":{}},{"cell_type":"code","source":["rf1 = RandomForestClassifier(max_depth=3, n_estimators=100, random_state=0)\nrf1.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(rf1.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(rf1.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 0.800\nAccuracy on test set: 0.755\n</div>"]}}],"execution_count":42},{"cell_type":"markdown","source":["After changing **max_depth =3**, the accuracy does not change alot. Thus, this model works well for default parameters."],"metadata":{}},{"cell_type":"markdown","source":["# Gradient Boosting"],"metadata":{}},{"cell_type":"code","source":["from sklearn.ensemble import GradientBoostingClassifier\ngb = GradientBoostingClassifier(random_state=0)\ngb.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(gb.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(gb.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 0.917\nAccuracy on test set: 0.792\n</div>"]}}],"execution_count":45},{"cell_type":"markdown","source":["It seems that it is overfitting. To reduce overfitting, we could either apply stronger pre-pruning by limiting the maximum depth or lower the learning rate:"],"metadata":{}},{"cell_type":"code","source":["gb1 = GradientBoostingClassifier(random_state=0, max_depth=1)\ngb1.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(gb1.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(gb1.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 0.804\nAccuracy on test set: 0.781\n</div>"]}}],"execution_count":47},{"cell_type":"code","source":["gb2 = GradientBoostingClassifier(random_state=0, learning_rate=0.01)\ngb2.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(gb2.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(gb2.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 0.802\nAccuracy on test set: 0.776\n</div>"]}}],"execution_count":48},{"cell_type":"markdown","source":["Both methods of decreasing the model complexity reduced the training set accuracy, as expected. However, in this case, none of these methods increased the generalization performance of the test set."],"metadata":{}},{"cell_type":"markdown","source":["# Support Vector Machine"],"metadata":{}},{"cell_type":"code","source":["from sklearn.svm import SVC\nsvc = SVC()\nsvc.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.2f}\".format(svc.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.2f}\".format(svc.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from &#39;auto&#39; to &#39;scale&#39; in version 0.22 to account better for unscaled features. Set gamma explicitly to &#39;auto&#39; or &#39;scale&#39; to avoid this warning.\n  &#34;avoid this warning.&#34;, FutureWarning)\nAccuracy on training set: 1.00\nAccuracy on test set: 0.65\n</div>"]}}],"execution_count":51},{"cell_type":"markdown","source":["The model overfits quite substantially, with a perfect score on the training set and only 65% accuracy on the test set.\n\nSVM requires all the features to vary on a similar scale. We will need to re-scale our data that all the features are approximately on the same scale:"],"metadata":{}},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)\n\nsvc = SVC()\nsvc.fit(X_train_scaled, y_train)\n\nprint(\"Accuracy on training set: {:.2f}\".format(svc.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.2f}\".format(svc.score(X_test_scaled, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n  return self.partial_fit(X, y)\n/databricks/python/lib/python3.7/site-packages/sklearn/preprocessing/data.py:334: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n  return self.partial_fit(X, y)\n/databricks/python/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from &#39;auto&#39; to &#39;scale&#39; in version 0.22 to account better for unscaled features. Set gamma explicitly to &#39;auto&#39; or &#39;scale&#39; to avoid this warning.\n  &#34;avoid this warning.&#34;, FutureWarning)\nAccuracy on training set: 0.77\nAccuracy on test set: 0.77\n</div>"]}}],"execution_count":53},{"cell_type":"markdown","source":["Scaling the data gives a huge difference! Now we are actually underfitting, where training and test set performance are quite similar but less close to 100% accuracy. \n\nFrom here, we can try increasing either C or gamma to fit a more complex model."],"metadata":{}},{"cell_type":"code","source":["svc = SVC(C=1000)\nsvc.fit(X_train_scaled, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(svc.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(svc.score(X_test_scaled, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from &#39;auto&#39; to &#39;scale&#39; in version 0.22 to account better for unscaled features. Set gamma explicitly to &#39;auto&#39; or &#39;scale&#39; to avoid this warning.\n  &#34;avoid this warning.&#34;, FutureWarning)\nAccuracy on training set: 0.790\nAccuracy on test set: 0.797\n</div>"]}}],"execution_count":55},{"cell_type":"markdown","source":["We get that the accuracy is improved by changing C"],"metadata":{}},{"cell_type":"markdown","source":["# k-Nearest Neighbors\n\nThe k-NN algorithm is arguably the simplest machine learning algorithm. Building the model consists only of storing the training data set. To make a prediction for a new data point, the algorithm finds the closest data points in the training data set — its “nearest neighbors.”"],"metadata":{}},{"cell_type":"code","source":["from sklearn.neighbors import KNeighborsClassifier\ntraining_accuracy = []\ntest_accuracy = []\n# try n_neighbors from 1 to 10\nneighbors_settings = range(1, 11)\nfor n_neighbors in neighbors_settings:\n    # build the model\n    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n    knn.fit(X_train, y_train)\n    # record training set accuracy\n    training_accuracy.append(knn.score(X_train, y_train))\n    # record test set accuracy\n    test_accuracy.append(knn.score(X_test, y_test))\nplt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\nplt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"n_neighbors\")\nplt.legend()\nplt.savefig('knn_compare_model')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":58},{"cell_type":"code","source":["print(\"the accuracy for training data: {:.3f}\".format(knn.score(X_train, y_train)))\nprint(\"the accuracy for test data: {:.3f}\".format(knn.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">the accuracy for training data: 0.774\nthe accuracy for test data: 0.771\n</div>"]}}],"execution_count":59},{"cell_type":"markdown","source":["The above plot shows the training and test set accuracy on the y-axis against the setting of n_neighbors on the x-axis. Considering if we choose one single nearest neighbor, the prediction on the training set is perfect. But when more neighbors are considered, the training accuracy drops, indicating that using the single nearest neighbor leads to a model that is too complex. The best performance is somewhere around 9 neighbors."],"metadata":{}},{"cell_type":"code","source":["knn = KNeighborsClassifier(n_neighbors=9)\nknn.fit(X_train, y_train)\nprint('Accuracy of K-NN classifier on training set: {:.2f}'.format(knn.score(X_train, y_train)))\nprint('Accuracy of K-NN classifier on test set: {:.2f}'.format(knn.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy of K-NN classifier on training set: 0.79\nAccuracy of K-NN classifier on test set: 0.78\n</div>"]}}],"execution_count":61},{"cell_type":"markdown","source":["#Deep Learning"],"metadata":{}},{"cell_type":"code","source":["from sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(random_state=42)\nmlp.fit(X_train, y_train)\nprint(\"Accuracy on training set: {:.2f}\".format(mlp.score(X_train, y_train)))\nprint(\"Accuracy on test set: {:.2f}\".format(mlp.score(X_test, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 0.73\nAccuracy on test set: 0.72\n</div>"]}}],"execution_count":63},{"cell_type":"markdown","source":["The accuracy of the Multilayer perceptrons (MLP) is not as good as the other models in ML, this is likely due to scaling of the data. Deep learning algorithms also expect all input features to vary in a similar way, and ideally to have a mean of 0, and a variance of 1. We must re-scale our data so that it fulfills these requirements."],"metadata":{}},{"cell_type":"code","source":["from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\n\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.fit_transform(X_test)\n\nmlp = MLPClassifier(random_state=0)\nmlp.fit(X_train_scaled, y_train)\n\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/databricks/python/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n/databricks/python/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/databricks/python/lib/python3.7/site-packages/sklearn/base.py:464: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n/databricks/python/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn&#39;t converged yet.\n  % self.max_iter, ConvergenceWarning)\nAccuracy on training set: 0.823\nAccuracy on test set: 0.802\n</div>"]}}],"execution_count":65},{"cell_type":"markdown","source":["Now try to increase the number of iterations"],"metadata":{}},{"cell_type":"code","source":["mlp = MLPClassifier(max_iter=1000, random_state=0)\nmlp.fit(X_train_scaled, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/python/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn&#39;t converged yet.\n  % self.max_iter, ConvergenceWarning)\nAccuracy on training set: 0.908\nAccuracy on test set: 0.792\n</div>"]}}],"execution_count":67},{"cell_type":"markdown","source":["Increasing the number of iterations only increased the training set performance, not the test set performance.\n\nLet’s increase the alpha parameter and add stronger regularization of the weights:"],"metadata":{}},{"cell_type":"code","source":["mlp = MLPClassifier(max_iter=1000, alpha=1, random_state=0)\nmlp.fit(X_train_scaled, y_train)\nprint(\"Accuracy on training set: {:.3f}\".format(mlp.score(X_train_scaled, y_train)))\nprint(\"Accuracy on test set: {:.3f}\".format(mlp.score(X_test_scaled, y_test)))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Accuracy on training set: 0.806\nAccuracy on test set: 0.797\n</div>"]}}],"execution_count":69},{"cell_type":"markdown","source":["The result sounds better, but we are not able to increase the test accuracy further.\n\nTherefore, our best model so far is default deep learning model after scaling."],"metadata":{}},{"cell_type":"markdown","source":["## Conclusion\nWe use many ML algorithm of classication and regression to analyse our data. This tells us how to control the complexity of each. \nAnd which algorithm will be better for these data."],"metadata":{}}],"metadata":{"name":"Diabete classification","notebookId":1568657345181868},"nbformat":4,"nbformat_minor":0}
